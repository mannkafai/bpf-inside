# TC的内核实现

## 0 前言

在[XDP的内核实现](./12-xdp.md)中我们分析了XDP的实现过程，通过XDP实现对ingress路径上网络数据包的控制。除XDP外，TC同样能够实现对网络数据包的控制。今天我们借助`tc`示例程序分析使用BPF进行流量控制的实现过程。

## 1 简介

TC(traffic control，流量控制)运行在网络栈中的`hook`点中，在INGRESS和EGRESS路径上对每个进入或离开的网络数据包进行控制，具有完全可观测性，在容器安全策略、转发和负载均衡、流量采集监测、网络数据包调度器预处理等方面广泛引用。

## 2 `tc`示例程序

### 2.1 BPF程序

BPF程序源码参见[tc.bpf.c](../src/tc.bpf.c)，主要内容如下：

```C
SEC("tc")
int tc_ingress(struct __sk_buff *ctx)
{
    void *data_end = (void *)(__u64)ctx->data_end;
    void *data = (void *)(__u64)ctx->data;
    struct ethhdr *l2;
    struct iphdr *l3;

    if (ctx->protocol != bpf_htons(ETH_P_IP))
        return TC_ACT_OK;

    l2 = data;
    if ((void *)(l2 + 1) > data_end)
        return TC_ACT_OK;

    l3 = (struct iphdr *)(l2 + 1);
    if ((void *)(l3 + 1) > data_end)
        return TC_ACT_OK;

    bpf_printk("Got IP packet: tot_len: %d, ttl: %d", bpf_ntohs(l3->tot_len), l3->ttl);
    return TC_ACT_OK;
}
```

该程序包含一个BPF程序`tc_ingress`，使用`tc`前缀。参数为`__sk_buff`类型。

### 2.2 用户程序

用户程序源码参见[tc.c](../src/tc.c)，主要内容如下：

#### 1 附加BPF程序

```C
int main(int argc, char **argv)
{
    DECLARE_LIBBPF_OPTS(bpf_tc_hook, tc_hook, 
            .ifindex = if_nametoindex("lo"), .attach_point = BPF_TC_INGRESS);
    DECLARE_LIBBPF_OPTS(bpf_tc_opts, tc_opts, .handle = 1, .priority = 1);
    bool hook_created = false;
    struct tc_bpf *skel;
    ...
    // 设置 libbpf 调试信息输出回调函数
    libbpf_set_print(libbpf_print_fn);
    // 打开并加载BPF程序
    skel = tc_bpf__open_and_load();
    if (!skel) { ... }
    // 创建tc_hook (qdisc)
    err = bpf_tc_hook_create(&tc_hook);
    if (!err) { ... }
    // 附加BPF程序
    tc_opts.prog_fd = bpf_program__fd(skel->progs.tc_ingress);
    err = bpf_tc_attach(&tc_hook, &tc_opts);
    if (err) { ... }
    // 设置`INT`处理函数
    if (signal(SIGINT, sig_int) == SIG_ERR) { ... }
    
	while (!exiting) {
        fprintf(stderr, ".");
        sleep(1);
	}
    tc_opts.flags = tc_opts.prog_fd = tc_opts.prog_id = 0;
    // 分离BPF程序
    err = bpf_tc_detach(&tc_hook, &tc_opts);
    if (err) { ... }

cleanup:
    if (hook_created)
        // 销毁tc_hook
        bpf_tc_hook_destroy(&tc_hook);
    // 销毁BPF程序
    tc_bpf__destroy(skel);
    return -err;
}
```

#### 2 读取数据过程

`tc_ingress` BPF程序获取网络包的长度和TTL后，通过 `bpf_printk` 输出到 `/sys/kernel/debug/tracing/trace_pipe` 文件中。

### 2.3 编译运行

使用cmake编译程序后运行，如下：

```bash
$ cd build
$ cmake ../src
$ make tc 
$ sudo ./tc 
libbpf: loading object 'tc_bpf' from buffer
...
Successfully started! Please run `sudo cat /sys/kernel/debug/tracing/trace_pipe` to see output of the BPF programs.
....
```

在`tc`程序运行的过程中打开另一个bash窗口查看输出结果，如下：

```bash
$ sudo cat /sys/kernel/debug/tracing/trace_pipe
            node-2528109 [002] d.s3. 571955.094487: bpf_trace_printk: Got IP packet: tot_len: 105, ttl: 64
            node-2528109 [002] d.s3. 571955.094609: bpf_trace_printk: Got IP packet: tot_len: 102, ttl: 64
            node-2528109 [002] d.s3. 571955.096523: bpf_trace_printk: Got IP packet: tot_len: 86, ttl: 64
            sshd-3305754 [001] d.s3. 571955.096600: bpf_trace_printk: Got IP packet: tot_len: 52, ttl: 64
            node-2528109 [002] d.s3. 571955.096642: bpf_trace_printk: Got IP packet: tot_len: 86, ttl: 64
...
```

## 3 附加BPF的过程

`tc.bpf.c`文件中BPF程序的SEC名称为 `SEC("tc")` ，在libbpf中的处理方式如下：

```C
// file: libbpf/src/libbpf.c
static const struct bpf_sec_def section_defs[] = {
    ...
    SEC_DEF("tc",   SCHED_CLS, 0, SEC_NONE),
    SEC_DEF("classifier",   SCHED_CLS, 0, SEC_NONE),
    SEC_DEF("action",   SCHED_ACT, 0, SEC_NONE),
    ...
};
```

`tc` 前缀不支持自动附加，需要通过手动方式附加。

### 3.1 创建`tc_hook`

```C
// file: ../src/tc.c
int main(int argc, char **argv)
{
    DECLARE_LIBBPF_OPTS(bpf_tc_hook, tc_hook, 
            .ifindex = if_nametoindex("lo"), .attach_point = BPF_TC_INGRESS);
    ...
    err = bpf_tc_hook_create(&tc_hook);
    ...
};
```

`tc_hook` 变量设置了创建`tc_hook`的信息, `.ifindex` 字段表示使用tc的网卡设备索引；`.attach_point` 字段表示tc的附加位置，支持`BPF_TC_INGRESS`, `BPF_TC_EGRESS`, `BPF_TC_CUSTOM` 三种方式。设置完成参数后，调用`bpf_tc_hook_create` 创建`tc_hook`。如下：

```C
// file: libbpf/src/netlink.c
int bpf_tc_hook_create(struct bpf_tc_hook *hook)
{
    // 参数检查，hook有效，`ifindex`字段必须设置
    if (!hook || !OPTS_VALID(hook, bpf_tc_hook) || OPTS_GET(hook, ifindex, 0) <= 0)
        return libbpf_err(-EINVAL);

    ret = tc_qdisc_create_excl(hook);
    return libbpf_err(ret);
}
```

`tc_qdisc_create_excl` 函数通过`tc_qdisc_modify`函数实现`tc_hook`的创建。`tc_qdisc_modify` 设置tc类型的netlink请求参数后，发送 `AF_UNSPEC:RTM_NEWQDISC` 类型netlink请求。如下：

```C
// file: libbpf/src/netlink.c
static int tc_qdisc_create_excl(struct bpf_tc_hook *hook)
{
    return tc_qdisc_modify(hook, RTM_NEWQDISC, NLM_F_CREATE | NLM_F_EXCL);
}

// file: libbpf/src/netlink.c
static int tc_qdisc_modify(struct bpf_tc_hook *hook, int cmd, int flags)
{
    qdisc_config_t config;
    struct libbpf_nla_req req;

    ret = attach_point_to_config(hook, &config);
    if (ret < 0) return ret;
    // netlink请求设置
    memset(&req, 0, sizeof(req));
    req.nh.nlmsg_len   = NLMSG_LENGTH(sizeof(struct tcmsg));
    req.nh.nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK | flags;
    req.nh.nlmsg_type  = cmd;
    // tc消息设置
    req.tc.tcm_family  = AF_UNSPEC;
    req.tc.tcm_ifindex = OPTS_GET(hook, ifindex, 0);

    ret = config(&req);
    if (ret < 0) return ret;

    return libbpf_netlink_send_recv(&req, NETLINK_ROUTE, NULL, NULL, NULL);
}
```

`attach_point_to_config` 函数获取TC附加点的配置函数。如下:

```C
// file: libbpf/src/netlink.c
static int attach_point_to_config(struct bpf_tc_hook *hook, qdisc_config_t *config)
{
    switch (OPTS_GET(hook, attach_point, 0)) {
    case BPF_TC_INGRESS:
    case BPF_TC_EGRESS:
    case BPF_TC_INGRESS | BPF_TC_EGRESS:
        if (OPTS_GET(hook, parent, 0)) return -EINVAL;
        *config = &clsact_config;
        return 0;
    case BPF_TC_CUSTOM:
        return -EOPNOTSUPP;
    default:
        return -EINVAL;
    }
}
```

libbpf目前只支持`BPF_TC_INGRESS`或`BPF_TC_EGRESS`类型的附加点，对应`clsact_config`函数，其实现如下：

```C
// file: libbpf/src/netlink.c
static int clsact_config(struct libbpf_nla_req *req)
{
    req->tc.tcm_parent = TC_H_CLSACT;
    req->tc.tcm_handle = TC_H_MAKE(TC_H_CLSACT, 0);
    return nlattr_add(req, TCA_KIND, "clsact", sizeof("clsact"));
}
```

设置TC消息的`parent`和`handle`，设置`TCA_KIND`属性。

### 3.2 附加`tc`

```C
// file: ../src/tc.c
int main(int argc, char **argv)
{
    DECLARE_LIBBPF_OPTS(bpf_tc_opts, tc_opts, .handle = 1, .priority = 1);
    ...
    tc_opts.prog_fd = bpf_program__fd(skel->progs.tc_ingress);
    err = bpf_tc_attach(&tc_hook, &tc_opts);
    ...
};
```

`tc_opts` 变量设置了附加TC的信息，设置完成参数后，调用`bpf_tc_attach` 附加TC，发送 `AF_UNSPEC:RTM_NEWTFILTER` 类型的netlink信息。如下：

```C
// file: libbpf/src/netlink.c
int bpf_tc_attach(const struct bpf_tc_hook *hook, struct bpf_tc_opts *opts)
{
    struct bpf_cb_ctx info = {};
    struct libbpf_nla_req req;
    ...

    // hook 和 opts 必须有效
    if (!hook || !opts || !OPTS_VALID(hook, bpf_tc_hook) || !OPTS_VALID(opts, bpf_tc_opts))
        return libbpf_err(-EINVAL);

    // 获取hook设置的参数
    ifindex      = OPTS_GET(hook, ifindex, 0);
    parent       = OPTS_GET(hook, parent, 0);
    attach_point = OPTS_GET(hook, attach_point, 0);
    // 获取opts设置的参数
    handle       = OPTS_GET(opts, handle, 0);
    priority     = OPTS_GET(opts, priority, 0);
    prog_fd      = OPTS_GET(opts, prog_fd, 0);
    prog_id      = OPTS_GET(opts, prog_id, 0);
    flags        = OPTS_GET(opts, flags, 0);

    // 设置的参数检查
    if (ifindex <= 0 || !prog_fd || prog_id) return libbpf_err(-EINVAL);
    if (priority > UINT16_MAX) return libbpf_err(-EINVAL);
    if (flags & ~BPF_TC_F_REPLACE) return libbpf_err(-EINVAL);

    // flags转换，protoc设置为所有的协议
    flags = (flags & BPF_TC_F_REPLACE) ? NLM_F_REPLACE : NLM_F_EXCL;
    protocol = ETH_P_ALL;

    // netlink请求设置
    memset(&req, 0, sizeof(req));
    req.nh.nlmsg_len   = NLMSG_LENGTH(sizeof(struct tcmsg));
    req.nh.nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK | NLM_F_CREATE | NLM_F_ECHO | flags;
    req.nh.nlmsg_type  = RTM_NEWTFILTER;
    req.tc.tcm_family  = AF_UNSPEC;
    req.tc.tcm_ifindex = ifindex;
    req.tc.tcm_handle  = handle;
    req.tc.tcm_info    = TC_H_MAKE(priority << 16, htons(protocol));

    // 获取TC消息中的`parent`
    ret = tc_get_tcm_parent(attach_point, &parent);
    if (ret < 0) return libbpf_err(ret);
    req.tc.tcm_parent = parent;

    // TCA_KIND消息设置
    ret = nlattr_add(&req, TCA_KIND, "bpf", sizeof("bpf"));
    if (ret < 0) return libbpf_err(ret);
    // TCA_OPTIONS选项设置
    nla = nlattr_begin_nested(&req, TCA_OPTIONS);
    if (!nla) return libbpf_err(-EMSGSIZE);
    // `TCA_BPF_FD`,`TCA_BPF_NAME`属性设置
    ret = tc_add_fd_and_name(&req, prog_fd);
    if (ret < 0) return libbpf_err(ret);
    // `TCA_BPF_FLAGS`属性设置，使用`DIRECT-ACTION`模式
    bpf_flags = TCA_BPF_FLAG_ACT_DIRECT;
    ret = nlattr_add(&req, TCA_BPF_FLAGS, &bpf_flags, sizeof(bpf_flags));
    if (ret < 0) return libbpf_err(ret);
    nlattr_end_nested(&req, nla);

    info.opts = opts;
    
    // 发送netlink消息，`get_tc_info`作为回调函数处理netlink返回的结果
    ret = libbpf_netlink_send_recv(&req, NETLINK_ROUTE, get_tc_info, NULL, &info);
    if (ret < 0) return libbpf_err(ret);
    // 不能处理netlink回复的消息，返回错误
    if (!info.processed) return libbpf_err(-ENOENT);
    return ret;
}
```

`tc_get_tcm_parent` 函数根据附件点设置`parent`，如下：

```C
// file: libbpf/src/netlink.c
static int tc_get_tcm_parent(enum bpf_tc_attach_point attach_point, __u32 *parent)
{
    switch (attach_point) {
    case BPF_TC_INGRESS:
    case BPF_TC_EGRESS:
        if (*parent) return -EINVAL;
        *parent = TC_H_MAKE(TC_H_CLSACT,  attach_point == BPF_TC_INGRESS ? 
                    TC_H_MIN_INGRESS : TC_H_MIN_EGRESS);
        break;
    case BPF_TC_CUSTOM:
        if (!*parent) return -EINVAL;
        break;
    default:
        return -EINVAL;
    }
    return 0;
}
```

### 3.3 分离`tc`

在程序退出时，我们需要分离设置的TC，`bpf_tc_detach()` 函数实现该功能，如下：

```C
// file: libbpf/src/netlink.c
int bpf_tc_detach(const struct bpf_tc_hook *hook, const struct bpf_tc_opts *opts)
{
    // opts必须存在
    if (!opts) return libbpf_err(-EINVAL);
    ret = __bpf_tc_detach(hook, opts, false);
    return libbpf_err(ret);
}
```

`__bpf_tc_detach` 函数实现分离TC，发送 `AF_UNSPEC:RTM_DELTFILTER` 类型的netlink信息。如下：

```C
// file: libbpf/src/netlink.c
static int __bpf_tc_detach(const struct bpf_tc_hook *hook,  const struct bpf_tc_opts *opts, const bool flush)
{
    ...
    // hook 和 opts 必须有效
    if (!hook || !OPTS_VALID(hook, bpf_tc_hook) || !OPTS_VALID(opts, bpf_tc_opts)) 
        return -EINVAL;

    // 获取hook设置的参数
    ifindex      = OPTS_GET(hook, ifindex, 0);
    parent       = OPTS_GET(hook, parent, 0);
    attach_point = OPTS_GET(hook, attach_point, 0);
    // 获取opts设置的参数
    handle       = OPTS_GET(opts, handle, 0);
    priority     = OPTS_GET(opts, priority, 0);
    prog_fd      = OPTS_GET(opts, prog_fd, 0);
    prog_id      = OPTS_GET(opts, prog_id, 0);
    flags        = OPTS_GET(opts, flags, 0);

    // 设置的参数检查
    if (ifindex <= 0 || flags || prog_fd || prog_id) return -EINVAL;
    if (priority > UINT16_MAX) return -EINVAL;
    if (!flush) { 
        if (!handle || !priority) return -EINVAL;
        protocol = ETH_P_ALL;
    } else {
        if (handle || priority) return -EINVAL;
    }

    // netlink请求设置
    memset(&req, 0, sizeof(req));
    req.nh.nlmsg_len   = NLMSG_LENGTH(sizeof(struct tcmsg));
    req.nh.nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK;
    req.nh.nlmsg_type  = RTM_DELTFILTER;
    req.tc.tcm_family  = AF_UNSPEC;
    req.tc.tcm_ifindex = ifindex;
    if (!flush) {
        req.tc.tcm_handle = handle;
        req.tc.tcm_info   = TC_H_MAKE(priority << 16, htons(protocol));
    }

    // 获取TC消息中的`parent`
    ret = tc_get_tcm_parent(attach_point, &parent);
    if (ret < 0) return ret;
    req.tc.tcm_parent = parent;

    if (!flush) {
        // 不刷新情况下，重新设置`TCA_KIND` 相关属性
        ret = nlattr_add(&req, TCA_KIND, "bpf", sizeof("bpf"));
        if (ret < 0) return ret;
    }

    return libbpf_netlink_send_recv(&req, NETLINK_ROUTE, NULL, NULL, NULL);
}
```

### 3.4 销毁`tc_hook`

在程序退出时，我们需要销毁创建的tc_hook，`bpf_tc_hook_destroy()` 函数实现该功能，如下：

```C
// file: libbpf/src/netlink.c
int bpf_tc_hook_destroy(struct bpf_tc_hook *hook)
{
    // 参数检查，hook有效，`ifindex`字段必须设置
    if (!hook || !OPTS_VALID(hook, bpf_tc_hook) || OPTS_GET(hook, ifindex, 0) <= 0)
        return libbpf_err(-EINVAL);

    switch (OPTS_GET(hook, attach_point, 0)) {
    case BPF_TC_INGRESS:
    case BPF_TC_EGRESS:
        return libbpf_err(__bpf_tc_detach(hook, NULL, true));
    case BPF_TC_INGRESS | BPF_TC_EGRESS:
        return libbpf_err(tc_qdisc_delete(hook));
    case BPF_TC_CUSTOM:
        return libbpf_err(-EOPNOTSUPP);
    default:
        return libbpf_err(-EINVAL);
    }
}
```

`tc_hook`设置的附加点只是`INGRESS`或`EGRESS`时，通过 `__bpf_tc_detach()` 函数删除。两者同时设置时，通过 `tc_qdisc_delete()` 函数删除，通过 `tc_qdisc_modify` 函数实现`tc_hook`的销毁。`tc_qdisc_modify` 设置tc类型的netlink请求参数后，发送 `AF_UNSPEC:RTM_DELQDISC` 类型netlink请求。如下：

```C
// file: libbpf/src/netlink.c
static int tc_qdisc_delete(struct bpf_tc_hook *hook)
{
    return tc_qdisc_modify(hook, RTM_DELQDISC, 0);
}
```

## 4 内核实现

### 4.1 创建`tc_hook`

#### (1) `netlink`接口

libbpf在创建`tc_hook`时，设置的 `网络协议:消息类型` 为 `AF_UNSPEC:RTM_NEWQDISC`, 在内核中相应的处理设置为：

```C
// file: net/sched/sch_api.c
static int __init pktsched_init(void)
{
    ...
    rtnl_register(PF_UNSPEC, RTM_NEWQDISC, tc_modify_qdisc, NULL, 0);
    rtnl_register(PF_UNSPEC, RTM_DELQDISC, tc_get_qdisc, NULL, 0);
    ...
}
subsys_initcall(pktsched_init);
```

`tc_modify_qdisc` 函数创建或替换`qdisc`，实现如下：

```C
// file: net/sched/sch_api.c
static int tc_modify_qdisc(struct sk_buff *skb, struct nlmsghdr *n, struct netlink_ext_ack *extack)
{
    struct net *net = sock_net(skb->sk);
    struct nlattr *tca[TCA_MAX + 1];
    struct net_device *dev;
    ...

replay:
	// 解析netlink请求信息
    err = nlmsg_parse_deprecated(n, sizeof(*tcm), tca, TCA_MAX, rtm_tca_policy, extack);
    if (err < 0) return err;

    // 获取tcm消息
    tcm = nlmsg_data(n);
    clid = tcm->tcm_parent;
    q = p = NULL;

    // 获取对应的网卡设备信息
    dev = __dev_get_by_index(net, tcm->tcm_ifindex);
    if (!dev) return -ENODEV;
    
    if (clid) {
        if (clid != TC_H_ROOT) {
            if (clid != TC_H_INGRESS) {
                // 不是`ROOT`和`INGRESS`时，根据层次关系确定`qdisc`
                p = qdisc_lookup(dev, TC_H_MAJ(clid));
                if (!p) { ... }
                q = qdisc_leaf(p, clid);
            } else if (dev_ingress_queue_create(dev)) {
                // `INGRESS`时，创建dev使用的 ingress qdisc
                q = dev_ingress_queue(dev)->qdisc_sleeping;
            }
        } else {
            // `ROOT` qdisc
            q = rtnl_dereference(dev->qdisc);
        }
        // 忽略默认的qdisc
        if (q && q->handle == 0) q = NULL;

        // qdisc存在时，检查设置的参数，确定是否创建或移植qdisc
        if (!q || !tcm->tcm_handle || q->handle != tcm->tcm_handle) { ... }
    } else {
        if (!tcm->tcm_handle) { ... }
        // `parent`未设置时，根据`handle`确定`qdisc`
        q = qdisc_lookup(dev, tcm->tcm_handle);
    }

    // 修改qdisc前的检查
    if (!q) { ... }
    if (n->nlmsg_flags & NLM_F_EXCL) { ... }
    // `KIND`名称设置时必须相同
    if (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], q->ops->id)) { ... }

    // 修改qdisc
    err = qdisc_change(q, tca, extack);
    if (err == 0)
        qdisc_notify(net, skb, n, clid, NULL, q, extack);
    return err;

create_n_graft:
    // 必须设置`NLM_F_CREATE`标记
    if (!(n->nlmsg_flags & NLM_F_CREATE)) { ... }
    
    if (clid == TC_H_INGRESS) {
        // `INGRESS`时，使用`dev->ingress_queue`, 不存在时，提示错误信息
        if (dev_ingress_queue(dev)) {
            // 创建`qdisc`
            q = qdisc_create(dev, dev_ingress_queue(dev), 
                    tcm->tcm_parent, tcm->tcm_parent, tca, &err, extack);
        } else {
            NL_SET_ERR_MSG(extack, "Cannot find ingress queue for specified device");
            err = -ENOENT;
        }
	} else {
        // 不是`INGRESS`时，确定`dev_queue`
        struct netdev_queue *dev_queue;

        // parent通过`select_queue`方式确定
        if (p && p->ops->cl_ops && p->ops->cl_ops->select_queue)
            dev_queue = p->ops->cl_ops->select_queue(p, tcm);
        else if (p)
            // 使用`parent`的`dev_queue`
            dev_queue = p->dev_queue;
        else
            // 使用`TX`队列
            dev_queue = netdev_get_tx_queue(dev, 0);

        // 创建`qdisc`
        q = qdisc_create(dev, dev_queue, tcm->tcm_parent, tcm->tcm_handle, tca, &err, extack);
    }
    // 创建失败时，`EAGAIN`时重新创建，否则退出
    if (q == NULL) {
        if (err == -EAGAIN) goto replay;
        return err;
    }

graft:
    // 移植`qdisc`
    err = qdisc_graft(dev, p, skb, n, clid, q, NULL, extack);
    if (err) {
        if (q) qdisc_put(q);
        return err;
    }
    return 0;
}
```

#### (2) 创建`qdisc`接口

`qdisc_create` 函数创建和初始化`qdisc`, 如下：

```C
// file: net/sched/sch_api.c
static struct Qdisc *qdisc_create(struct net_device *dev, struct netdev_queue *dev_queue, 
        u32 parent, u32 handle, struct nlattr **tca, int *errp, struct netlink_ext_ack *extack)
{
    struct nlattr *kind = tca[TCA_KIND];
    struct Qdisc *sch;
    struct Qdisc_ops *ops;

    // 从`qdisc_base`中查找，通过`register_qdisc()`注册
    ops = qdisc_lookup_ops(kind);
    ...
    err = -ENOENT;
    if (!ops) { ... }
    // 创建`qdisc`
    sch = qdisc_alloc(dev_queue, ops, extack);
    if (IS_ERR(sch)) { ... }
    // 设置`parent`
    sch->parent = parent;

    // 确定`handle`
    if (handle == TC_H_INGRESS) {
        ...
        handle = TC_H_MAKE(TC_H_INGRESS, 0);
    } else {
        if (handle == 0) {
            // 分配一个唯一的handle，范围为`[8000-FFFF]:0000`
            handle = qdisc_alloc_handle(dev)
        }
        // 网卡设备只有一个发送队列时，设置`ONETXQUEUE`标记
        if (!netif_is_multiqueue(dev))
            sch->flags |= TCQ_F_ONETXQUEUE;
    }
    // 设置`handle`
    sch->handle = handle;

    // 发送队列长度检查
    if ((dev->priv_flags & IFF_NO_QUEUE) && (dev->tx_queue_len == 0)) {
        dev->tx_queue_len = DEFAULT_TX_QUEUE_LEN;
        netdev_info(dev, "Caught tx_queue_len zero misconfig\n");
    }
    
    // 存在TCA_INGRESS_BLOCK,TCA_EGRESS_BLOCK选项时，设置ingress_block/egress_block
    err = qdisc_block_indexes_set(sch, tca, extack);
    if (err) goto err_out3;

    // 存在STAB选项时，进行相关设置
    if (tca[TCA_STAB]) {
        stab = qdisc_get_stab(tca[TCA_STAB], extack);
        if (IS_ERR(stab)) { ... }
        // stab设置
        rcu_assign_pointer(sch->stab, stab);
    }
    
    // qdisc初始化
    if (ops->init) {
        err = ops->init(sch, tca[TCA_OPTIONS], extack);
        if (err != 0) goto err_out4;
    }

    // 存在`RATE`选项时，生成速率估算
    if (tca[TCA_RATE]) {
        err = -EOPNOTSUPP;
        // 不能在多队列上附加速率限制
        if (sch->flags & TCQ_F_MQROOT) { ... }
        // 生成速率估算器
        err = gen_new_estimator(&sch->bstats, sch->cpu_bstats, &sch->rate_est,
                    NULL, true, tca[TCA_RATE]);
    }
    // 添加到`dev`中
    qdisc_hash_add(sch, false);
    trace_qdisc_create(ops, dev, parent);

    return sch;
    ...
}
```

#### (3) 移植`qdisc`接口

`qdisc_graft` 函数将新创建的`qdisc`移植到`parent`或`root`，移植成功后释放旧的qdisc, 如下：

```C
// file: net/sched/sch_api.c
static int qdisc_graft(struct net_device *dev, struct Qdisc *parent, struct sk_buff *skb, struct nlmsghdr *n, 
            u32 classid, struct Qdisc *new, struct Qdisc *old, struct netlink_ext_ack *extack)
{
    struct Qdisc *q = old;
    struct net *net = dev_net(dev);

    if (parent == NULL) {
        // parent不存在时，表示root
        unsigned int i, num_q, ingress;
        ingress = 0;
        num_q = dev->num_tx_queues;

        if ((q && q->flags & TCQ_F_INGRESS) || (new && new->flags & TCQ_F_INGRESS)) {
            // `INGRESS`时，队列数量为1
            num_q = 1;
            ingress = 1;
            if (!dev_ingress_queue(dev)) { ...  }
        }
        // 网卡设备启动时，关闭网卡
        if (dev->flags & IFF_UP) dev_deactivate(dev);

        // 网卡设备卸载迁移`root`
        qdisc_offload_graft_root(dev, new, old, extack);

        // 支持附加时，跳过迁移过程
        if (new && new->ops->attach && !ingress) goto skip;

        // 迁移qdisc，ingress或 不支持附加的egress
        for (i = 0; i < num_q; i++) {
            // 获取`dev_queue`, ingress队列或TX队列
            struct netdev_queue *dev_queue = dev_ingress_queue(dev);
            if (!ingress) dev_queue = netdev_get_tx_queue(dev, i);
            // 将顶级 qdisc 附加到设备队列
            old = dev_graft_qdisc(dev_queue, new);

            // 增加新的qdisc的引用计数，释放旧的qdisc
            if (new && i > 0) qdisc_refcount_inc(new);
            if (!ingress) qdisc_put(old);
        }

skip:
        if (!ingress) {
            old = rtnl_dereference(dev->qdisc);
            if (new && !new->ops->attach)
                qdisc_refcount_inc(new);
            // 设置网卡设备的qdisc
            rcu_assign_pointer(dev->qdisc, new ? : &noop_qdisc);
            notify_and_destroy(net, skb, n, classid, old, new, extack);
            // 附加新的qdisc
            if (new && new->ops->attach)
                new->ops->attach(new);
        } else {
            // ingress时，通知并释放old
            notify_and_destroy(net, skb, n, classid, old, new, extack);
        }

        // 网卡设备启动时，激活网卡
        if (dev->flags & IFF_UP) dev_activate(dev);
    } else {
        // parent存在时
        const struct Qdisc_class_ops *cops = parent->ops->cl_ops;
        unsigned long cl;
        // 仅当父类无锁时，支持之类无锁
        if (new && (new->flags & TCQ_F_NOLOCK) && !(parent->flags & TCQ_F_NOLOCK))
            qdisc_clear_nolock(new);

        // 支持性检查
        if (!cops || !cops->graft) return -EOPNOTSUPP;

        // 获取parent
        cl = cops->find(parent, classid);
        if (!cl) { ... }
        if (new && new->ops == &noqueue_qdisc_ops) { ... }
        // 迁移接口
        err = cops->graft(parent, cl, new, &old, extack);
        if (err) return err;
        // 通知并释放old
        notify_and_destroy(net, skb, n, classid, old, new, extack);
    }
}
```

`dev_graft_qdisc` 函数附加顶级qdisc到设备队列中，如下：

```C
// file: net/sched/sch_generic.c
struct Qdisc *dev_graft_qdisc(struct netdev_queue *dev_queue, struct Qdisc *qdisc)
{
    struct Qdisc *oqdisc = dev_queue->qdisc_sleeping;
	spinlock_t *root_lock;

    root_lock = qdisc_lock(oqdisc);
    spin_lock_bh(root_lock);
    // 默认`noop_qdisc`
    if (qdisc == NULL) qdisc = &noop_qdisc;
    dev_queue->qdisc_sleeping = qdisc;
    rcu_assign_pointer(dev_queue->qdisc, &noop_qdisc);

    spin_unlock_bh(root_lock);
    return oqdisc;
}
```

#### (4) 修改`qdisc`接口

`qdisc_change` 函数修改qdisc设置, 如下：

```C
// file: net/sched/sch_api.c
static int qdisc_change(struct Qdisc *sch, struct nlattr **tca, struct netlink_ext_ack *extack)
{
    struct qdisc_size_table *ostab, *stab = NULL;
    int err = 0;

    // 修改`OPTIONS`
    if (tca[TCA_OPTIONS]) {
        // `change`接口必须存在，不允许修改`INGRESS_BLOCK`或`EGRESS_BLOCK`
        if (!sch->ops->change) { ... }
        if (tca[TCA_INGRESS_BLOCK] || tca[TCA_EGRESS_BLOCK]) { ...  }
        // `change`接口调用
        err = sch->ops->change(sch, tca[TCA_OPTIONS], extack);
        if (err) return err;
    }

    // 修改`STAB`
    if (tca[TCA_STAB]) {
        stab = qdisc_get_stab(tca[TCA_STAB], extack);
        if (IS_ERR(stab)) return PTR_ERR(stab);
    }
    ostab = rtnl_dereference(sch->stab);
    rcu_assign_pointer(sch->stab, stab);
    qdisc_put_stab(ostab);

    // 修改`RATE`
    if (tca[TCA_RATE]) {
        if (sch->flags & TCQ_F_MQROOT) goto out;
        // 替换速率估算器
        gen_replace_estimator(&sch->bstats, sch->cpu_bstats, &sch->rate_est,
            NULL, true, tca[TCA_RATE]);
    }
out:
    return 0;
}
```

### 4.2 销毁`tc_hook`

#### (1) `netlink`接口

libbpf在销毁`tc_hook`时，设置的 `网络协议:消息类型` 为 `AF_UNSPEC:RTM_DELQDISC`, 在内核中相应的处理设置为`tc_get_qdisc`，该函数删除或获取`qdisc`，实现如下：

```C
// file: net/sched/sch_api.c
static int tc_get_qdisc(struct sk_buff *skb, struct nlmsghdr *n, struct netlink_ext_ack *extack)
{
    struct net *net = sock_net(skb->sk);
    struct tcmsg *tcm = nlmsg_data(n);
    ...

    // 解析netlink请求信息
    err = nlmsg_parse_deprecated(n, sizeof(*tcm), tca, TCA_MAX, rtm_tca_policy, extack);
    if (err < 0) return err;

    // 获取对应的网卡设备信息
    dev = __dev_get_by_index(net, tcm->tcm_ifindex);
    if (!dev) return -ENODEV;

    clid = tcm->tcm_parent;
    if (clid) {
        if (clid != TC_H_ROOT) {
            if (TC_H_MAJ(clid) != TC_H_MAJ(TC_H_INGRESS)) {
                p = qdisc_lookup(dev, TC_H_MAJ(clid));
                if (!p) { ... }
                q = qdisc_leaf(p, clid);
            } else if (dev_ingress_queue(dev)) {
                q = dev_ingress_queue(dev)->qdisc_sleeping;
            }
        } else {
            q = rtnl_dereference(dev->qdisc);
        }
        // qdisc检查
        if (!q) { ... }
        if (tcm->tcm_handle && q->handle != tcm->tcm_handle) { ... }
    } else {
        // 根据`handle`查找qdisc
        q = qdisc_lookup(dev, tcm->tcm_handle);
        if (!q) { ... }
    }
    // `KIND`名称必须相同
    if (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], q->ops->id)) { ... }

    if (n->nlmsg_type == RTM_DELQDISC) {
        // 删除`qdisc`，前提检查
        if (!clid) { ...  }
        if (q->handle == 0) { ... }
        // 将`NULL`移植到旧的qdisc中
        err = qdisc_graft(dev, p, skb, n, clid, NULL, q, extack);
        if (err != 0) return err;
    } else {
        // 其他情况发送qdisc通知消息
        qdisc_notify(net, skb, n, clid, NULL, q, NULL);
    }
    return 0;
}
```

#### (2) 销毁`qdisc`接口

在`qdisc_graft()`函数中调用`notify_and_destroy()`函数，在其中删除旧的`qdisc`，如下：

```C
// file: net/sched/sch_api.c
static void notify_and_destroy(struct net *net, struct sk_buff *skb, ...)
        // netlink通知消息
    --> if (new || old) qdisc_notify(net, skb, n, clid, old, new, extack);
        // 释放旧的`qdisc`
    --> if (old) qdisc_put(old);
        --> qdisc_destroy(qdisc);
```

`qdisc_destroy` 函数销毁创建的`qdisc`，如下：

```C
// file: net/sched/sch_api.c
static void qdisc_destroy(struct Qdisc *qdisc)
{
    const struct Qdisc_ops  *ops = qdisc->ops;

#ifdef CONFIG_NET_SCHED
    // 从hash中移除`qdisc`
    qdisc_hash_del(qdisc);
    // 释放`stab`
    qdisc_put_stab(rtnl_dereference(qdisc->stab));
#endif
    // 删除速率估算器
    gen_kill_estimator(&qdisc->rate_est);

    // 重置`qdisc`， 调用`ops->reset`接口，清空队列中的`gso_skb`和`skb_bad_txq`
    qdisc_reset(qdisc);

    // 调用`ops->destroy`接口
    if (ops->destroy) ops->destroy(qdisc);

    module_put(ops->owner);
    netdev_put(qdisc_dev(qdisc), &qdisc->dev_tracker);

    trace_qdisc_destroy(qdisc);
    // 释放`qdisc`
    call_rcu(&qdisc->rcu, qdisc_free_cb);
}
```

### 4.3 `clsact`的实现

Linux内核支持多种类型的`qdisc`，通过`qdisc`实现网络数据包的分类。使用BPF程序时，使用`clsact`类型的qdisc，如下：

```C
// file: libbpf/src/netlink.c
static int clsact_config(struct libbpf_nla_req *req)
{
    req->tc.tcm_parent = TC_H_CLSACT;
    req->tc.tcm_handle = TC_H_MAKE(TC_H_CLSACT, 0);
    return nlattr_add(req, TCA_KIND, "clsact", sizeof("clsact"));
}
```

`clsact`类型的qdisc，定义如下：

```C
// file: net/sched/sch_ingress.c
static const struct Qdisc_class_ops clsact_class_ops = {
	.flags		=	QDISC_CLASS_OPS_DOIT_UNLOCKED,
	.leaf		=	ingress_leaf,
	.find		=	clsact_find,
	.walk		=	ingress_walk,
	.tcf_block	=	clsact_tcf_block,
	.bind_tcf	=	clsact_bind_filter,
	.unbind_tcf	=	ingress_unbind_filter,
};

// file: net/sched/sch_ingress.c
static struct Qdisc_ops clsact_qdisc_ops __read_mostly = {
	.cl_ops			=	&clsact_class_ops,
	.id			=	"clsact",
	.priv_size		=	sizeof(struct clsact_sched_data),
	.static_flags		=	TCQ_F_INGRESS | TCQ_F_CPUSTATS,
	.init			=	clsact_init,
	.destroy		=	clsact_destroy,
	.dump			=	ingress_dump,
	.ingress_block_set	=	clsact_ingress_block_set,
	.egress_block_set	=	clsact_egress_block_set,
	.ingress_block_get	=	clsact_ingress_block_get,
	.egress_block_get	=	clsact_egress_block_get,
	.owner			=	THIS_MODULE,
};
```

在`initcall`阶段注册的，如下：

```C
// file: net/sched/sch_ingress.c
static int __init ingress_module_init(void)
{
    ret = register_qdisc(&ingress_qdisc_ops);
    ...
    ret = register_qdisc(&clsact_qdisc_ops);
    ...
}
module_init(ingress_module_init);
```

#### (1) 初始化过程

在创建`qdisc`后，调用`.init`接口进行初始化。`clsact_init`函数实现`clsact`类型的qdisc的初始化，如下：

```C
// file: net/sched/sch_ingress.c
static int clsact_init(struct Qdisc *sch, struct nlattr *opt, struct netlink_ext_ack *extack)
{
    struct clsact_sched_data *q = qdisc_priv(sch);
    struct net_device *dev = qdisc_dev(sch);

    // 类型必须为`TC_H_CLSACT`
    if (sch->parent != TC_H_CLSACT) return -EOPNOTSUPP;

    // 增加`ingress_needed_key`和`egress_needed_key`计数
    net_inc_ingress_queue();
    net_inc_egress_queue();

    // miniqp_ingress初始化
    mini_qdisc_pair_init(&q->miniqp_ingress, sch, &dev->miniq_ingress);
    // ingress_block扩展信息设置
    q->ingress_block_info.binder_type = FLOW_BLOCK_BINDER_TYPE_CLSACT_INGRESS;
    q->ingress_block_info.chain_head_change = clsact_chain_head_change;
    q->ingress_block_info.chain_head_change_priv = &q->miniqp_ingress;
    // ingress_block获取扩展信息
    err = tcf_block_get_ext(&q->ingress_block, sch, &q->ingress_block_info, extack);
    if (err) return err;
    // miniqp_ingress初始block
    mini_qdisc_pair_block_init(&q->miniqp_ingress, q->ingress_block);

    // miniqp_egress初始化
    mini_qdisc_pair_init(&q->miniqp_egress, sch, &dev->miniq_egress);
    q->egress_block_info.binder_type = FLOW_BLOCK_BINDER_TYPE_CLSACT_EGRESS;
    q->egress_block_info.chain_head_change = clsact_chain_head_change;
    q->egress_block_info.chain_head_change_priv = &q->miniqp_egress;
    return tcf_block_get_ext(&q->egress_block, sch, &q->egress_block_info, extack);
}
```

`miniqp_ingress` 和 `miniqp_egress` 变量使用 `struct mini_Qdisc_pair`类型，如下：

```C
// file: include/net/sch_generic.h
struct mini_Qdisc_pair {
    struct mini_Qdisc miniq1;
    struct mini_Qdisc miniq2;
    struct mini_Qdisc __rcu **p_miniq;
};
```

`struct mini_Qdisc` 结构是服务于 `ingress/clsact Qdisc` 的特定需要而存在的。定义如下：

```C
// file: include/net/sch_generic.h
struct mini_Qdisc {
    struct tcf_proto *filter_list;
    struct tcf_block *block;
    struct gnet_stats_basic_sync __percpu *cpu_bstats;
    struct gnet_stats_queue	__percpu *cpu_qstats;
    unsigned long rcu_state;
};
```

`mini_qdisc_pair_init` 函数初始化`mini_Qdisc_pair`结构，如下：

```C
// file: net/sched/sch_generic.c
void mini_qdisc_pair_init(struct mini_Qdisc_pair *miniqp, struct Qdisc *qdisc, 
        struct mini_Qdisc __rcu **p_miniq)
{
    miniqp->miniq1.cpu_bstats = qdisc->cpu_bstats;
    miniqp->miniq1.cpu_qstats = qdisc->cpu_qstats;
    miniqp->miniq2.cpu_bstats = qdisc->cpu_bstats;
    miniqp->miniq2.cpu_qstats = qdisc->cpu_qstats;
    miniqp->miniq1.rcu_state = get_state_synchronize_rcu();
    miniqp->miniq2.rcu_state = miniqp->miniq1.rcu_state;
    miniqp->p_miniq = p_miniq;
}
```

`tcf_block_get_ext` 函数获取`tcf_block`额外的设置信息，如下：

```C
// file: net/sched/cls_api.c
int tcf_block_get_ext(struct tcf_block **p_block, struct Qdisc *q,
            struct tcf_block_ext_info *ei, struct netlink_ext_ack *extack)
{
    struct net *net = qdisc_net(q);
    struct tcf_block *block = NULL;

    if (ei->block_index)
        // `block_index` 不为0，表示共享的block
        block = tcf_block_refcnt_get(net, ei->block_index);

    if (!block) {
        // block不存在时，创建
        block = tcf_block_create(net, q, ei->block_index, extack);
        if (IS_ERR(block)) return PTR_ERR(block);
        // 共享的block，添加到网络命名空间
        if (tcf_block_shared(block)) {
            err = tcf_block_insert(block, net, extack);
            if (err) goto err_block_insert;
        }
    }
    // 创建`block`拥有者
    err = tcf_block_owner_add(block, q, ei->binder_type);
    if (err) goto err_block_owner_add;

    // 检查是否保留dst
    tcf_block_owner_netif_keep_dst(block, q, ei->binder_type);

    // chain0添加`tcf_filter`到`block`中
    err = tcf_chain0_head_change_cb_add(block, ei, extack);
    if (err) goto err_chain0_head_change_cb_add;

    // offload绑定
    err = tcf_block_offload_bind(block, q, ei, extack);
    if (err) goto err_block_offload_bind;

    *p_block = block;
    return 0;
    ...
}
```

`tcf_chain0_head_change_cb_add` 函数添加`tcf_filter`到`tcf_block`中，如下：

```C
// file: net/sched/cls_api.c
static int tcf_chain0_head_change_cb_add(struct tcf_block *block, 
            struct tcf_block_ext_info *ei, struct netlink_ext_ack *extack)
{
    struct tcf_filter_chain_list_item *item;
    struct tcf_chain *chain0;

    // 创建`tcf_filter`, 设置`chain_head_change`回调函数和参数值
    item = kmalloc(sizeof(*item), GFP_KERNEL);
    if (!item) { ... }
    item->chain_head_change = ei->chain_head_change;
    item->chain_head_change_priv = ei->chain_head_change_priv;

    mutex_lock(&block->lock);
    chain0 = block->chain0.chain;
    if (chain0)
        tcf_chain_hold(chain0);
    else
        // 添加到`filter`列表中
        list_add(&item->list, &block->chain0.filter_chain_list);
    mutex_unlock(&block->lock);

    if (chain0) {
        // chain0存在时
        struct tcf_proto *tp_head;

        mutex_lock(&chain0->filter_chain_lock);
        // tcp_chain存在时，调用`chain_head_change`回调函数
        tp_head = tcf_chain_dereference(chain0->filter_chain, chain0);
        if (tp_head) tcf_chain_head_change_item(item, tp_head);

        // 同样添加到`filter`列表中
        mutex_lock(&block->lock);
        list_add(&item->list, &block->chain0.filter_chain_list);
        mutex_unlock(&block->lock);

        mutex_unlock(&chain0->filter_chain_lock);
        tcf_chain_put(chain0);
    }
    return 0;
}
```

#### (2) 销毁过程

在销毁`Qdisc`时调用`.destroy`接口，销毁`clsact`。如下：

```C
// file: net/sched/sch_ingress.c
static void clsact_destroy(struct Qdisc *sch)
{
    struct clsact_sched_data *q = qdisc_priv(sch);
    if (sch->parent != TC_H_CLSACT) return;

    // 释放`egress_block`和`ingress_block`额外设置
    tcf_block_put_ext(q->egress_block, sch, &q->egress_block_info);
    tcf_block_put_ext(q->ingress_block, sch, &q->ingress_block_info);

    // 减少`ingress_needed_key`和`egress_needed_key`计数
    net_dec_ingress_queue();
    net_dec_egress_queue();
}
```

`tcf_block_put_ext` 函数释放`tcf_block`设置的额外信息，如下：

```C
// file: net/sched/cls_api.c
void tcf_block_put_ext(struct tcf_block *block, struct Qdisc *q, struct tcf_block_ext_info *ei)
{
    if (!block) return;
    // 删除`tcf_filter`
    tcf_chain0_head_change_cb_del(block, ei);
    // 删除`block`拥有者
    tcf_block_owner_del(block, q, ei->binder_type);
    // 释放`tcf_block`
    __tcf_block_put(block, q, ei, true);
}
```

`tcf_chain0_head_change_cb_del` 函数删除`tcf_filter`，如下：

```C
// file: net/sched/cls_api.c
static void tcf_chain0_head_change_cb_del(struct tcf_block *block, struct tcf_block_ext_info *ei)
{
    struct tcf_filter_chain_list_item *item;

    mutex_lock(&block->lock);
    list_for_each_entry(item, &block->chain0.filter_chain_list, list) {
        if ((!ei->chain_head_change && !ei->chain_head_change_priv) ||
            (item->chain_head_change == ei->chain_head_change &&
            item->chain_head_change_priv == ei->chain_head_change_priv)) {
            // `chain0`存在时，调用`chain_head_change`回调函数
            if (block->chain0.chain) tcf_chain_head_change_item(item, NULL);
            // 从列表中删除`tcf_filter`
            list_del(&item->list);
            mutex_unlock(&block->lock);

            // 释放chain_item
            kfree(item);
            return;
        }
    }
    mutex_unlock(&block->lock);
    WARN_ON(1);
}
```

#### (3) `chain0`的设置过程

`clsact_chain_head_change` 是`clsact`设置的回调函数，在`block->chain0.chain` 变化时调用，实现`dev->miniq_[in/e]gress`的设置。实现如下：

```C
// file: net/sched/sch_ingress.c
static void clsact_chain_head_change(struct tcf_proto *tp_head, void *priv)
{
    struct mini_Qdisc_pair *miniqp = priv;
    mini_qdisc_pair_swap(miniqp, tp_head);
};
```

`mini_qdisc_pair_swap` 函数修改`mini_Qdisc_pair`设置，如下：

```C
// file: net/sched/sch_ingress.c
void mini_qdisc_pair_swap(struct mini_Qdisc_pair *miniqp, struct tcf_proto *tp_head)
{
    struct mini_Qdisc *miniq_old = rcu_dereference_protected(*miniqp->p_miniq, 1);
    struct mini_Qdisc *miniq;

    if (!tp_head) {
        // `tp_head`为NULL时，设置`p_miniq`为NULL
        RCU_INIT_POINTER(*miniqp->p_miniq, NULL);
    } else {
        // 交换`miniq1`和`miniq2`
        miniq = miniq_old != &miniqp->miniq1 ?
            &miniqp->miniq1 : &miniqp->miniq2;
        // RCU同步
        if (IS_ENABLED(CONFIG_PREEMPT_RT))
            cond_synchronize_rcu(miniq->rcu_state);
        else if (!poll_state_synchronize_rcu(miniq->rcu_state))
            synchronize_rcu_expedited();

        // 设置miniq的过滤列表后，设置`p_miniq`为选择的miniq
        miniq->filter_list = tp_head;
        rcu_assign_pointer(*miniqp->p_miniq, miniq);
    }

    // 更新RCU状态
    if (miniq_old)
        miniq_old->rcu_state = start_poll_synchronize_rcu();
}
```

### 4.4 创建`tfilter`接口

#### （1）`netlink`接口

libbpf在附加`tc`时，设置的`网络协议:消息类型`为 `AF_UNSPEC:RTM_NEWTFILTER`, 在内核中相应的处理设置为：

```C
// file: net/sched/cls_api.c
static int __init tc_filter_init(void)
{
    ...
    rtnl_register(PF_UNSPEC, RTM_NEWTFILTER, tc_new_tfilter, NULL, RTNL_FLAG_DOIT_UNLOCKED);
    rtnl_register(PF_UNSPEC, RTM_DELTFILTER, tc_del_tfilter, NULL, RTNL_FLAG_DOIT_UNLOCKED);
    ...
}
subsys_initcall(tc_filter_init);
```

`tc_new_tfilter` 函数创建`tfilter`, 实现如下：

```C
// file: net/sched/cls_api.c
static int tc_new_tfilter(struct sk_buff *skb, struct nlmsghdr *n, struct netlink_ext_ack *extack)
{
    struct net *net = sock_net(skb->sk);
    struct nlattr *tca[TCA_MAX + 1];
    struct tcmsg *t;
    ...

replay:
    tp_created = 0;

    // 解析netlink请求信息
    err = nlmsg_parse_deprecated(n, sizeof(*t), tca, TCA_MAX, rtm_tca_policy, extack);
    if (err < 0) return err;

    // 获取tcmsg,获取设置优先级、协议、parent等字段
    t = nlmsg_data(n);
    protocol = TC_H_MIN(t->tcm_info);
    prio = TC_H_MAJ(t->tcm_info);
    prio_allocate = false;
    parent = t->tcm_parent;
    ...

    if (prio == 0) {
        // 用户空间没有设置优先级时，设置默认优先级
        if (n->nlmsg_flags & NLM_F_CREATE) {
            prio = TC_H_MAKE(0x80000000U, 0U);
            prio_allocate = true;
        } else { ... }
    }

    // 查找qdisc，获取网卡设备后，获取qdisc
    err = __tcf_qdisc_find(net, &q, &parent, t->tcm_ifindex, false, extack);
    if (err) return err;

    // 检查kind是否过长
    if (tcf_proto_check_kind(tca[TCA_KIND], name)) { ... }
    ...

    // 获取classid，`q->ops->cl_ops->find(...)`接口，对应`clsact`中的`MIN_INGRESS/MIN_EGRESS`
    err = __tcf_qdisc_cl_find(q, parent, &cl, t->tcm_ifindex, extack);
    if (err) goto errout;

    // 获取tcf_block，`q->ops->cl_ops->tcf_block(...)`接口，对应`clsact`中的`ingress_block/egress_block`
    block = __tcf_block_find(net, q, cl, t->tcm_ifindex, t->tcm_block_index, extack);
    if (IS_ERR(block)) { ...}
    block->classid = parent;

    // 获取chain_index
    chain_index = tca[TCA_CHAIN] ? nla_get_u32(tca[TCA_CHAIN]) : 0;
    if (chain_index > TC_ACT_EXT_VAL_MASK) { ... }
    // 获取block中的chain，不存在时创建，index为0时，设置`block->chain0.chain`
    chain = tcf_chain_get(block, chain_index, true);
    if (!chain) { ... }

    mutex_lock(&chain->filter_chain_lock);
    // 获取chain中的指定优先级/协议的tcf_proto
    tp = tcf_chain_tp_find(chain, &chain_info, protocol, prio, prio_allocate);
    if (IS_ERR(tp)) { ... }

    if (tp == NULL) {
        // tcf_proto不存在时，创建新的
        struct tcf_proto *tp_new = NULL;

        // chain正在清空时，退出
        if (chain->flushing) { ... }

        // 检查用户空间参数设置，必须设置`KIND`、协议字段，设置`CREATE`标记
        if (tca[TCA_KIND] == NULL || !protocol) { ... }
        if (!(n->nlmsg_flags & NLM_F_CREATE)) { ... }

        // 自动调整优先级
        if (prio_allocate)
            prio = tcf_auto_prio(tcf_chain_tp_prev(chain, &chain_info));

        mutex_unlock(&chain->filter_chain_lock);
        // 创建`tcf_proto`
        tp_new = tcf_proto_create(name, protocol, prio, chain, rtnl_held, extack);
        if (IS_ERR(tp_new)) { ... }

        tp_created = 1;
        // 将`tcf_proto`插入chain中
        tp = tcf_chain_tp_insert_unique(chain, tp_new, protocol, prio, rtnl_held);
        if (IS_ERR(tp)) { ... }
    } else {
        mutex_unlock(&chain->filter_chain_lock);
    }

    // 设置`KIND`时，检查是否kind是否相同
    if (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], tp->ops->kind)) { ... }

    // 获取 filter_handler
    fh = tp->ops->get(tp, t->tcm_handle);

    // 检查用户空间设置的flags是否正确
    if (!fh) {
        if (!(n->nlmsg_flags & NLM_F_CREATE)) { ... }
    } else if (n->nlmsg_flags & NLM_F_EXCL) { ... }

    // chain模板时，必须为同一个过滤类别
    if (chain->tmplt_ops && chain->tmplt_ops != tp->ops) { ... }

    // flags标记设置
    if (!(n->nlmsg_flags & NLM_F_CREATE)) flags |= TCA_ACT_FLAGS_REPLACE;
    if (!rtnl_held) flags |= TCA_ACT_FLAGS_NO_RTNL;
    if (is_qdisc_ingress(parent)) flags |= TCA_ACT_FLAGS_AT_INGRESS;

    // `.change`接口，修改过滤处理
    err = tp->ops->change(net, skb, tp, cl, t->tcm_handle, tca, &fh, flags, extack);
    if (err == 0) {
        // netlink通知
        tfilter_notify(net, skb, n, tp, block, q, parent, fh, RTM_NEWTFILTER, false, rtnl_held, extack);
        tfilter_put(tp, fh);
        if (q) q->flags &= ~TCQ_F_CAN_BYPASS;
    }

errout:
    // 出现错误时，删除`tcf_proto`
    if (err && tp_created) 
        tcf_chain_tp_delete_empty(chain, tp, rtnl_held, NULL);
errout_tp:
    if (chain) {
        if (tp && !IS_ERR(tp)) tcf_proto_put(tp, rtnl_held, NULL);
        if (!tp_created) tcf_chain_put(chain);
    }
    tcf_block_release(q, block, rtnl_held);

    if (rtnl_held) rtnl_unlock();

    // 并发清空chain时，导致rtnl锁出现`EAGAIN`错误，重新处理
    if (err == -EAGAIN) {
        rtnl_held = true;
        goto replay;
    }
    return err;

errout_locked:
    mutex_unlock(&chain->filter_chain_lock);
    goto errout;
}
```

#### （2）获取`chain`

`tcf_chain_get` 函数获取block中的`chain`，不存在时创建，如下：

```C
// file: net/sched/cls_api.c
static struct tcf_chain *tcf_chain_get(struct tcf_block *block, u32 chain_index, bool create)
    --> __tcf_chain_get(block, chain_index, true, true);
        --> chain = tcf_chain_lookup(block, chain_index);
            // chain存在时，增加引用计数
        --> if (chain) tcf_chain_hold(chain);
            // 不存在且指定创建时，创建chain
        --> else chain = tcf_chain_create(block, chain_index);
```

`tcf_chain_create` 函数创建chain，索引为0时修改设置为chain0，如下：

```C
// file: net/sched/cls_api.c
static struct tcf_chain *tcf_chain_create(struct tcf_block *block, u32 chain_index)
{
    struct tcf_chain *chain;
    ASSERT_BLOCK_LOCKED(block);

    // 分配内存
    chain = kzalloc(sizeof(*chain), GFP_KERNEL);
    if (!chain) return NULL;
    // 添加到block中
    list_add_tail_rcu(&chain->list, &block->chain_list);
    mutex_init(&chain->filter_chain_lock);
    chain->block = block;
    chain->index = chain_index;
    chain->refcnt = 1;
    if (!chain->index)
        // index为0时，修改block->chain0
        block->chain0.chain = chain;
    return chain;
}
```

#### （3）创建`tcf_proto`

`tcf_proto_create` 函数创建`tcf_proto`，如下：

```C
// file: net/sched/cls_api.c
static struct tcf_proto *tcf_proto_create(const char *kind, u32 protocol, u32 prio, 
            struct tcf_chain *chain, bool rtnl_held, struct netlink_ext_ack *extack)
{
    struct tcf_proto *tp;
    int err;

    tp = kzalloc(sizeof(*tp), GFP_KERNEL);
    if (!tp) return ERR_PTR(-ENOBUFS);

    // 根据名称获取`ops`, 从`tcf_proto_base`列表中获取，通过`register_tcf_proto_ops()`注册的`classfilter`类型
    tp->ops = tcf_proto_lookup_ops(kind, rtnl_held, extack);
    if (IS_ERR(tp->ops)) { ... }

    // 设置tcf_proto属性
    tp->classify = tp->ops->classify;
    tp->protocol = protocol;
    tp->prio = prio;
    tp->chain = chain;
    spin_lock_init(&tp->lock);
    refcount_set(&tp->refcnt, 1);

    // 初始化tcf_proto
    err = tp->ops->init(tp);
    if (err) { ... }
    return tp;

errout:
    kfree(tp);
    return ERR_PTR(err);
}
```

#### （4）插入`tcf_proto`

`tcf_chain_tp_insert_unique` 函数尝试插入`tcf_proto`，如下：

```C
// file: net/sched/cls_api.c
static struct tcf_proto *tcf_chain_tp_insert_unique(struct tcf_chain *chain, struct tcf_proto *tp_new,
                            u32 protocol, u32 prio, bool rtnl_held)
{
    struct tcf_chain_info chain_info;
    struct tcf_proto *tp;
    int err = 0;

    mutex_lock(&chain->filter_chain_lock);

    // `tcf_proto`在`proto_destroy_ht`列表中，销毁`tcf_proto`
    if (tcf_proto_exists_destroying(chain, tp_new)) {
        mutex_unlock(&chain->filter_chain_lock);
        tcf_proto_destroy(tp_new, rtnl_held, false, NULL);
        return ERR_PTR(-EAGAIN);
    }
    // 获取指定 `优先级:协议` 的`tcf_proto`
    tp = tcf_chain_tp_find(chain, &chain_info, protocol, prio, false);
    if (!tp)
        // 不存在时，添加到chain中
        err = tcf_chain_tp_insert(chain, &chain_info, tp_new);
    mutex_unlock(&chain->filter_chain_lock);

    if (tp) {
        // 存在时，删除新的`tcf_proto`，返回旧的`tcf_proto`
        tcf_proto_destroy(tp_new, rtnl_held, false, NULL);
        tp_new = tp;
    } else if (err) {
        // 添加过程中出现错误，删除新的`tcf_proto`，返回错误码
        tcf_proto_destroy(tp_new, rtnl_held, false, NULL);
        tp_new = ERR_PTR(err);
    }
    return tp_new;
}
```

`tcf_chain_tp_insert` 函数在指定的位置插入`tcf_proto`，是`chain`中的第一个时，通知`chain`发生了变化。如下：

```C
// file: net/sched/cls_api.c
static int tcf_chain_tp_insert(struct tcf_chain *chain, struct tcf_chain_info *chain_info, struct tcf_proto *tp)
{
    if (chain->flushing) return -EAGAIN;

    // next设置
    RCU_INIT_POINTER(tp->next, tcf_chain_tp_prev(chain, chain_info));
    // prev指向head时，通知chain发生了变化
    if (*chain_info->pprev == chain->filter_chain)
        tcf_chain0_head_change(chain, tp);
    tcf_proto_get(tp);
    // prev设置
    rcu_assign_pointer(*chain_info->pprev, tp);
    return 0;
}
```

`tcf_chain0_head_change` 函数判断为chain0时，通知`tcf_chain`发生了变化，如下：

```C
// file: net/sched/cls_api.c
static void tcf_chain0_head_change(struct tcf_chain *chain, struct tcf_proto *tp_head)
{
    struct tcf_filter_chain_list_item *item;
    struct tcf_block *block = chain->block;

    // 判断是否为chain0
    if (chain->index) return;

    mutex_lock(&block->lock);
    // 遍历`filter_chain_list`，逐个通知chain0发生了变化
    list_for_each_entry(item, &block->chain0.filter_chain_list, list)
        tcf_chain_head_change_item(item, tp_head);
    mutex_unlock(&block->lock);
}
```

#### (5) `chain`的netlink接口

在创建`tfilter`过程中创建chain，除此之外，Linux内核还提供了专门操作chain的接口。如下：

```C
// file: net/sched/cls_api.c
static int __init tc_filter_init(void)
{
    ...
    rtnl_register(PF_UNSPEC, RTM_NEWCHAIN, tc_ctl_chain, NULL, 0);
    rtnl_register(PF_UNSPEC, RTM_DELCHAIN, tc_ctl_chain, NULL, 0);
    rtnl_register(PF_UNSPEC, RTM_GETCHAIN, tc_ctl_chain, tc_dump_chain, 0);
    ...
}
subsys_initcall(tc_filter_init);
```

`tc_ctl_chain` 函数实现chain的添加、删除、获取操作，如下：

```C
// file: net/sched/cls_api.c
static int tc_ctl_chain(struct sk_buff *skb, struct nlmsghdr *n, struct netlink_ext_ack *extack)
{
    struct net *net = sock_net(skb->sk);
    struct nlattr *tca[TCA_MAX + 1];
    struct tcmsg *t;
    ...

replay:
    q = NULL;
    // 解析netlink请求信息
    err = nlmsg_parse_deprecated(n, sizeof(*t), tca, TCA_MAX, rtm_tca_policy, extack);
    if (err < 0) return err;

    t = nlmsg_data(n);
    parent = t->tcm_parent;
    cl = 0;

    // 获取block、qdisc等信息
    block = tcf_block_find(net, &q, &parent, &cl, t->tcm_ifindex, t->tcm_block_index, extack);
    if (IS_ERR(block)) return PTR_ERR(block);

    // 获取chain_index
    chain_index = tca[TCA_CHAIN] ? nla_get_u32(tca[TCA_CHAIN]) : 0;
    if (chain_index > TC_ACT_EXT_VAL_MASK) { ... }

    mutex_lock(&block->lock);
    // 获取chain
    chain = tcf_chain_lookup(block, chain_index);
    if (n->nlmsg_type == RTM_NEWCHAIN) {
        // 创建CHAIN时检查
        if (chain) {
            // chain存在时，仅由action使用时，增加引用计数。否则返回错误信息(EEXIST)
            if (tcf_chain_held_by_acts_only(chain)) {
                tcf_chain_hold(chain);
            } else { ... }
        } else {
            // chain不存在时，需要设置`NLM_F_CREATE`标记
            if (!(n->nlmsg_flags & NLM_F_CREATE)) { ... }
            // 创建chain 
            chain = tcf_chain_create(block, chain_index);
            if (!chain) { ... }
        }
    } else {
        // 其他情形检查，chain必须存在，不能仅由action使用
        if (!chain || tcf_chain_held_by_acts_only(chain)) { ... }
        tcf_chain_hold(chain);
    }

    if (n->nlmsg_type == RTM_NEWCHAIN) {
        tcf_chain_hold(chain);
        // 设置显式创建标志
        chain->explicitly_created = true;
    }
    mutex_unlock(&block->lock);

    switch (n->nlmsg_type) {
    case RTM_NEWCHAIN:
        // 设置`tca[TCA_KIND]`时，设置chain模板，失败时释放chain
        err = tc_chain_tmplt_add(chain, net, tca, extack);
        if (err) {
            tcf_chain_put_explicitly_created(chain);
            goto errout;
        }
        // 通知chain结果
        tc_chain_notify(chain, NULL, 0, NLM_F_CREATE | NLM_F_EXCL, RTM_NEWCHAIN, false, extack);
        break;
    case RTM_DELCHAIN:
        tfilter_notify_chain(net, skb, block, q, parent, n, chain, RTM_DELTFILTER, extack);
        // 删除之前刷新chain
        tcf_chain_flush(chain, true);
        tcf_chain_put_explicitly_created(chain);
        break;
    case RTM_GETCHAIN:
        err = tc_chain_notify(chain, skb, n->nlmsg_seq, n->nlmsg_flags, n->nlmsg_type, true, extack);
        if (err < 0) ...
        break;
    default:
        err = -EOPNOTSUPP;
        NL_SET_ERR_MSG(extack, "Unsupported message type");
        goto errout;
    }
errout:
    tcf_chain_put(chain);
errout_block:
    tcf_block_release(q, block, true);
    // `EAGAIN`错误时重新整个流程
    if (err == -EAGAIN) goto replay;
	return err;

errout_block_locked:
    mutex_unlock(&block->lock);
    goto errout_block;
}
```

### 4.5 删除`tfilter`接口

#### （1）`netlink`接口

libbpf在分离`tc`时，设置的`网络协议:消息类型`为 `AF_UNSPEC:RTM_DELTFILTER` , 在内核中相应的处理函数为 `tc_del_tfilter`, 实现如下：

```C
// file: net/sched/cls_api.c
static int tc_del_tfilter(struct sk_buff *skb, struct nlmsghdr *n, struct netlink_ext_ack *extack)
{
    struct net *net = sock_net(skb->sk);
    struct nlattr *tca[TCA_MAX + 1];
    struct tcmsg *t;
    ...

    // 解析netlink请求信息
    err = nlmsg_parse_deprecated(n, sizeof(*t), tca, TCA_MAX, rtm_tca_policy, extack);
    if (err < 0) return err;

    // 获取tcmsg, 获取设置优先级、协议、parent等字段
    t = nlmsg_data(n);
    protocol = TC_H_MIN(t->tcm_info);
    prio = TC_H_MAJ(t->tcm_info);
    parent = t->tcm_parent;

    // 用户空间设置的参数检查，设置 protocol、handle、kind时不能清空filters
    if (prio == 0 && (protocol || t->tcm_handle || tca[TCA_KIND])) { ... }

    // 查找qdisc，获取网卡设备后，获取qdisc
    err = __tcf_qdisc_find(net, &q, &parent, t->tcm_ifindex, false, extack);
    if (err) return err;
    // 检查kind是否过长
    if (tcf_proto_check_kind(tca[TCA_KIND], name)) { ... }
    ...

    // 获取classid，q->ops->cl_ops->find(...)接口，对应`clsact`中的`MIN_INGRESS/MIN_EGRESS`
    err = __tcf_qdisc_cl_find(q, parent, &cl, t->tcm_ifindex, extack);
    if (err) goto errout;

    // 获取tcf_block，q->ops->cl_ops->tcf_block(...)接口，对应`clsact`中的`ingress_block/egress_block`
    block = __tcf_block_find(net, q, cl, t->tcm_ifindex, t->tcm_block_index, extack);
    if (IS_ERR(block)) { ...}

    // 获取chain_index
    chain_index = tca[TCA_CHAIN] ? nla_get_u32(tca[TCA_CHAIN]) : 0;
    if (chain_index > TC_ACT_EXT_VAL_MASK) { ... }
    // 获取block中的chain
    chain = tcf_chain_get(block, chain_index, false);
    // 用户空间请求清空不存在的chain时，返回成功
    if (!chain) { ... }

    if (prio == 0) {
        tfilter_notify_chain(net, skb, block, q, parent, n, chain, RTM_DELTFILTER, extack);
        // 清空chain
        tcf_chain_flush(chain, rtnl_held);
        err = 0;
        goto errout;
    }

    mutex_lock(&chain->filter_chain_lock);
    // 获取指定`优先级:协议`的`tcf_proto`
    tp = tcf_chain_tp_find(chain, &chain_info, protocol, prio, false);
    // 指定`优先级:协议`的`tcf_proto`不存在或者类别不匹配时，提示错误信息后退出
    if (!tp || IS_ERR(tp)) { ... }
    else if (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], tp->ops->kind)) { ... }
    else if (t->tcm_handle == 0) { 
        // 添加`tcf_proto`到`block->proto_destroy_ht`列表中
        tcf_proto_signal_destroying(chain, tp);
        // 删除`tcf_proto`，是`filter_chain`中的第一个时，通知`chain`发送了变化
        tcf_chain_tp_remove(chain, &chain_info, tp);
        mutex_unlock(&chain->filter_chain_lock);

        // 释放`tcf_proto`
        tcf_proto_put(tp, rtnl_held, NULL);
        tfilter_notify(net, skb, n, tp, block, q, parent, fh, RTM_DELTFILTER, false, rtnl_held, extack);
        err = 0;
        goto errout;
    }
    
    // 获取 filter_handler
    fh = tp->ops->get(tp, t->tcm_handle);

    // 指定的 filter_handler 不存在时，退出
    if (!fh) { ... } 
    else {
        bool last;
        // 删除`tfilter`并发送netlink信息。通过`tp->ops->delete()`接口删除
        err = tfilter_del_notify(net, skb, n, tp, block, q, parent, fh, false, &last, rtnl_held, extack);
        if (err) goto errout;

        // 最后一个filter时，删除`tcf_proto`
        if (last) tcf_chain_tp_delete_empty(chain, tp, rtnl_held, extack);
    }

errout:
    if (chain) {
        // `tcf_proto`存在时，释放`tcf_proto`
        if (tp && !IS_ERR(tp)) tcf_proto_put(tp, rtnl_held, NULL);
        // 释放`chain`
        tcf_chain_put(chain);
    }
    // 释放`tcf_block`
    tcf_block_release(q, block, rtnl_held);

    if (rtnl_held) rtnl_unlock();
    return err;
errout_locked:
    mutex_unlock(&chain->filter_chain_lock);
    goto errout;
}
```

#### （2）释放`tcf_proto`

`tcf_chain_tp_remove` 函数删除`tcf_proto`, 是chain0时，通知chain0发生了变化。如下

```C
// file: net/sched/cls_api.c
static void tcf_chain_tp_remove(struct tcf_chain *chain, struct tcf_chain_info *chain_info, struct tcf_proto *tp)
{
    // 获取下一个`tcf_proto`
    struct tcf_proto *next = tcf_chain_dereference(chain_info->next, chain);

    tcf_proto_mark_delete(tp);
    // 删除的`tcf_proto`是第一个时，通知chain发生了变化
    if (tp == chain->filter_chain)
        tcf_chain0_head_change(chain, next);
    RCU_INIT_POINTER(*chain_info->pprev, next);
}
```

`tcf_chain_tp_delete_empty`函数同样实现删除`tcf_proto`功能，自动查找和删除`tcf_proto`。如下：

```C
// file: net/sched/cls_api.c
static void tcf_chain_tp_delete_empty(struct tcf_chain *chain, struct tcf_proto *tp, 
            bool rtnl_held, struct netlink_ext_ack *extack)
{
    ...

    mutex_lock(&chain->filter_chain_lock);

    // 自动从chain列表中查找和删除`tcf_proto`
    for (pprev = &chain->filter_chain; 
        (tp_iter = tcf_chain_dereference(*pprev, chain)); pprev = &tp_iter->next) {
        if (tp_iter == tp) {
            chain_info.pprev = pprev;
            chain_info.next = tp_iter->next;
            WARN_ON(tp_iter->deleting);
            break;
        }
    }
    // 并发情况下，验证`tcf_proto`存在，没有新的filter使用
    if (!tp_iter || !tcf_proto_check_delete(tp)) {
        mutex_unlock(&chain->filter_chain_lock);
        return;
    }
    
    tcf_proto_signal_destroying(chain, tp);
    next = tcf_chain_dereference(chain_info.next, chain);
    // 删除的`tcf_proto`是第一个时，通知chain发生了变化
    if (tp == chain->filter_chain)
        tcf_chain0_head_change(chain, next);
    RCU_INIT_POINTER(*chain_info.pprev, next);
    mutex_unlock(&chain->filter_chain_lock);

    tcf_proto_put(tp, rtnl_held, extack);
}
```

`tcf_proto_put` 函数释放`tcf_proto`，如下：

```C
// file: net/sched/cls_api.c
static void tcf_proto_put(struct tcf_proto *tp, bool rtnl_held, struct netlink_ext_ack *extack)
{
    if (refcount_dec_and_test(&tp->refcnt))
        tcf_proto_destroy(tp, rtnl_held, true, extack);
}

// file: net/sched/cls_api.c
static void tcf_proto_destroy(struct tcf_proto *tp, bool rtnl_held, bool sig_destroy, struct netlink_ext_ack *extack)
{
    // `destroy`接口
    tp->ops->destroy(tp, rtnl_held, extack);
    if (sig_destroy)
        tcf_proto_signal_destroyed(tp->chain, tp);
    tcf_chain_put(tp->chain);
    module_put(tp->ops->owner);
    kfree_rcu(tp, rcu);
}
```

#### （3）释放`tcf_chain`

`tcf_chain_put` 函数释放`tcf_chain`, 在引用计数为0时，分离和释放`chain`。如下：

```C
// file: net/sched/cls_api.c
static void tcf_chain_put(struct tcf_chain *chain)
{
    __tcf_chain_put(chain, false, false);
}
// file: net/sched/cls_api.c
static void __tcf_chain_put(struct tcf_chain *chain, bool by_act, bool explicitly_created)
{
    struct tcf_block *block = chain->block;
    ...

    mutex_lock(&block->lock);
    // 明确创建状态时，进行判断
    if (explicitly_created) { ... }

    // 减少`action`引用计数
    if (by_act) chain->action_refcnt--;

    // 减少引用计数
    refcnt = --chain->refcnt;
    tmplt_ops = chain->tmplt_ops;
    tmplt_priv = chain->tmplt_priv;

    // 最后一个非action 引用时，触发通知消息
    if (refcnt - chain->action_refcnt == 0 && !by_act) { ... }

    // 引用计数为0时，分离chain
    if (refcnt == 0)
        free_block = tcf_chain_detach(chain);
    mutex_unlock(&block->lock);

    if (refcnt == 0) {
        // 引用计数为0时，删除模板ops，销毁`chain`
        tc_chain_tmplt_del(tmplt_ops, tmplt_priv);
        tcf_chain_destroy(chain, free_block);
    }
}
```

`tcf_chain_detach` 函数检查block是否能够安全释放，如下：

```C
// file: net/sched/cls_api.c
static bool tcf_chain_detach(struct tcf_chain *chain)
{
    struct tcf_block *block = chain->block;
    ASSERT_BLOCK_LOCKED(block);

    // 从列表中移除`chain`
    list_del_rcu(&chain->list);
    // index为0时，设置chain0为null
    if (!chain->index)
        block->chain0.chain = NULL;

    // chain列表为空，引用计数为0时，表示可以删除block
    if (list_empty(&block->chain_list) && refcount_read(&block->refcnt) == 0)
        return true;
    return false;
}
```

#### （4）释放`tcf_block`和`qdisc`

`tcf_block_release` 函数释放`tcf_block`和`qdisc`，如下：

```C
// file: net/sched/cls_api.c
static void tcf_block_release(struct Qdisc *q, struct tcf_block *block, bool rtnl_held)
{
    // block存在时，释放
    if (!IS_ERR_OR_NULL(block))
        tcf_block_refcnt_put(block, rtnl_held);

    // qdisc存在时，释放
    if (q) {
        if (rtnl_held) qdisc_put(q);
        else qdisc_put_unlocked(q);
    }
}
```

`tcf_block_refcnt_put` 函数减少引用计数后，计数为0时释放。如下：

```C
// file: net/sched/cls_api.c
static void tcf_block_refcnt_put(struct tcf_block *block, bool rtnl_held)
{
    __tcf_block_put(block, NULL, NULL, rtnl_held);
}
// file: net/sched/cls_api.c
static void __tcf_block_put(struct tcf_block *block, struct Qdisc *q, 
            struct tcf_block_ext_info *ei, bool rtnl_held)
{
    if (refcount_dec_and_mutex_lock(&block->refcnt, &block->lock)) {
        // chain列表为空时，需要手动释放
        bool free_block = list_empty(&block->chain_list);
        mutex_unlock(&block->lock);
        // 共享block时，移除
        if (tcf_block_shared(block))
            tcf_block_remove(block, block->net);

        // qdisc存在时，解除offload绑定
        if (q) tcf_block_offload_unbind(block, q, ei);

        if (free_block)
            // 手动释放block
            tcf_block_destroy(block);
        else
            // 最后一个block引用时，清空chain_list
            tcf_block_flush_all_chains(block, rtnl_held);
    } else if (q) {
        tcf_block_offload_unbind(block, q, ei);
    }
}
```

`tcf_block_flush_all_chains` 函数清空所有的chain列表，如下：

```C
// file: net/sched/cls_api.c
static void tcf_block_flush_all_chains(struct tcf_block *block, bool rtnl_held)
{
    struct tcf_chain *chain;
    for (chain = tcf_get_next_chain(block, NULL); chain; chain = tcf_get_next_chain(block, chain)) {
        // 释放和清空chain
        tcf_chain_put_explicitly_created(chain);
        tcf_chain_flush(chain, rtnl_held);
    }
}
```

### 4.6 `cls_bpf`的实现

Linux内核支持多种类型的`tcf_proto`，通过`tcf_proto`实现网络数据包的分类。使用BPF程序时，使用`bpf`类型的`tcf_proto`，如下：

```C
// file: libbpf/src/netlink.c
int bpf_tc_attach(const struct bpf_tc_hook *hook, struct bpf_tc_opts *opts)
{
    ...
    ret = nlattr_add(&req, TCA_KIND, "bpf", sizeof("bpf"));
    ...
}
```

`bpf`类型的`tcf_proto`，定义如下：

```C
// file: net/sched/cls_bpf.c
static struct tcf_proto_ops cls_bpf_ops __read_mostly = {
	.kind		=	"bpf",
	.owner		=	THIS_MODULE,
	.classify	=	cls_bpf_classify,
	.init		=	cls_bpf_init,
	.destroy	=	cls_bpf_destroy,
	.get		=	cls_bpf_get,
	.change		=	cls_bpf_change,
	.delete		=	cls_bpf_delete,
	.walk		=	cls_bpf_walk,
	.reoffload	=	cls_bpf_reoffload,
	.dump		=	cls_bpf_dump,
	.bind_class	=	cls_bpf_bind_class,
};
```

在`initcall`阶段注册的，如下：

```C
// file: net/sched/cls_bpf.c
static int __init cls_bpf_init_mod(void)
{
    return register_tcf_proto_ops(&cls_bpf_ops);
}
module_init(cls_bpf_init_mod);
```

#### (1) `init`接口实现

`cls_bpf_init` 函数创建并初始化`cls_bpf_head`，如下：

```C
// file: net/sched/cls_bpf.c
static int cls_bpf_init(struct tcf_proto *tp)
{
    struct cls_bpf_head *head;

    head = kzalloc(sizeof(*head), GFP_KERNEL);
    if (head == NULL)return -ENOBUFS;

    INIT_LIST_HEAD_RCU(&head->plist);
    idr_init(&head->handle_idr);
    rcu_assign_pointer(tp->root, head);
    return 0;
}
```

#### (2) `get`接口实现

`cls_bpf_get` 函数获取设置的`cls_bpf`程序，如下：

```C
// file: net/sched/cls_bpf.c
static void *cls_bpf_get(struct tcf_proto *tp, u32 handle)
{
    struct cls_bpf_head *head = rtnl_dereference(tp->root);
    struct cls_bpf_prog *prog;

    list_for_each_entry(prog, &head->plist, link) {
        if (prog->handle == handle)
            return prog;
    }
    return NULL;
}
```

#### (3) `change`接口实现

`cls_bpf_change` 函数创建或修改`cls_bpf`程序，如下：

```C
// file: net/sched/cls_bpf.c
static int cls_bpf_change(struct net *net, struct sk_buff *in_skb, struct tcf_proto *tp, unsigned long base,
     u32 handle, struct nlattr **tca, void **arg, u32 flags, struct netlink_ext_ack *extack)
{
    struct cls_bpf_head *head = rtnl_dereference(tp->root);
    struct cls_bpf_prog *oldprog = *arg;
    struct nlattr *tb[TCA_BPF_MAX + 1];
    struct cls_bpf_prog *prog;
    int ret;

    // 解析netlink请求信息·
    if (tca[TCA_OPTIONS] == NULL) return -EINVAL;
    ret = nla_parse_nested_deprecated(tb, TCA_BPF_MAX, tca[TCA_OPTIONS], bpf_policy, NULL);
    if (ret < 0) return ret;

    // 创建 cls_bpf_prog
    prog = kzalloc(sizeof(*prog), GFP_KERNEL);
    if (!prog) return -ENOBUFS;

    ret = tcf_exts_init(&prog->exts, net, TCA_BPF_ACT, TCA_BPF_POLICE);
    if (ret < 0) goto errout;

    // 旧bpf程序、handle存在时，检查handle是否相同
    if (oldprog) {
        if (handle && oldprog->handle != handle) { ... }
    }

    // 从`handle_idr`中获取ID
    if (handle == 0) {
        handle = 1;
        ret = idr_alloc_u32(&head->handle_idr, prog, &handle, INT_MAX, GFP_KERNEL);
    } else if (!oldprog) {
        ret = idr_alloc_u32(&head->handle_idr, prog, &handle, handle, GFP_KERNEL);
    }
    if (ret) goto errout;

    // 设置新bpf程序的handle
    prog->handle = handle;

    // 设置cls_bpf程序参数
    ret = cls_bpf_set_parms(net, tp, prog, base, tb, tca[TCA_RATE], flags, extack);
    if (ret < 0) goto errout_idr;

    // offload替换cls_bpf程序
    ret = cls_bpf_offload(tp, prog, oldprog, extack);
    if (ret) goto errout_parms;

    if (!tc_in_hw(prog->gen_flags)) 
        prog->gen_flags |= TCA_CLS_FLAGS_NOT_IN_HW;

    if (oldprog) {
        // 替换旧的cls_bpf程序
        idr_replace(&head->handle_idr, prog, handle);
        list_replace_rcu(&oldprog->link, &prog->link);
        // 清理旧的cls_bpf程序
        tcf_unbind_filter(tp, &oldprog->res);
        tcf_exts_get_net(&oldprog->exts);
        tcf_queue_work(&oldprog->rwork, cls_bpf_delete_prog_work);
    } else {
        // 添加新的cls_bpf程序到列表中
        list_add_rcu(&prog->link, &head->plist);
    }
    // 设置返回结果为新的cls_bpf程序
    *arg = prog;
    return 0;
errout_parms:
    cls_bpf_free_parms(prog);
errout_idr:
    if (!oldprog) idr_remove(&head->handle_idr, prog->handle);
errout:
    tcf_exts_destroy(&prog->exts);
    kfree(prog);
    return ret;
}
```

`cls_bpf_set_parms` 函数解析netlink请求参数，设置bpf程序，如下：

```C
// file: net/sched/cls_bpf.c
static int cls_bpf_set_parms(struct net *net, struct tcf_proto *tp, struct cls_bpf_prog *prog, 
    unsigned long base, struct nlattr **tb, struct nlattr *est, u32 flags, struct netlink_ext_ack *extack)
{
    bool is_bpf, is_ebpf, have_exts = false;
    u32 gen_flags = 0;
    int ret;

    // 支持BPF指令和fd两种方式，单不能同时支持
    is_bpf = tb[TCA_BPF_OPS_LEN] && tb[TCA_BPF_OPS];
    is_ebpf = tb[TCA_BPF_FD];
    if ((!is_bpf && !is_ebpf) || (is_bpf && is_ebpf)) return -EINVAL;

    // cls_act检查
    ret = tcf_exts_validate(net, tp, tb, est, &prog->exts, flags, extack);
    if (ret < 0) return ret;

    // direct-action 检查
    if (tb[TCA_BPF_FLAGS]) {   
        u32 bpf_flags = nla_get_u32(tb[TCA_BPF_FLAGS]);
        if (bpf_flags & ~TCA_BPF_FLAG_ACT_DIRECT) return -EINVAL;
        have_exts = bpf_flags & TCA_BPF_FLAG_ACT_DIRECT;
    }
    // GEN_FLAGS检查，支持 VERBOSE,SKIP_HW,SKIP_SW 三种标记设置，SKIP_HW,SKIP_SW为互斥选项
    if (tb[TCA_BPF_FLAGS_GEN]) {
        gen_flags = nla_get_u32(tb[TCA_BPF_FLAGS_GEN]);
        if (gen_flags & ~CLS_BPF_SUPPORTED_GEN_FLAGS || !tc_flags_valid(gen_flags))
            return -EINVAL;
    }

    prog->exts_integrated = have_exts;
    prog->gen_flags = gen_flags;

    // 从BPF指令 或 fd 加载cls_bpf程序
    ret = is_bpf ? cls_bpf_prog_from_ops(tb, prog) :
                   cls_bpf_prog_from_efd(tb, prog, gen_flags, tp);
    if (ret < 0) return ret;

    // 设置`CLASSID`时，绑定filter
    if (tb[TCA_BPF_CLASSID]) {
        prog->res.classid = nla_get_u32(tb[TCA_BPF_CLASSID]);
        tcf_bind_filter(tp, &prog->res, base);
    }
    return 0;
}
```

`cls_bpf_prog_from_ops` 函数通过BPF指令的方式加载BPF程序，如下：

```C
// file: net/sched/cls_bpf.c
static int cls_bpf_prog_from_ops(struct nlattr **tb, struct cls_bpf_prog *prog)
{
    struct sock_filter *bpf_ops;
    struct sock_fprog_kern fprog_tmp;
    struct bpf_prog *fp;
    u16 bpf_size, bpf_num_ops;
    int ret;

    // 获取和检查BPF程序指令数量，不能超过4096条指令，每条指令为`sock_filter`类型
    bpf_num_ops = nla_get_u16(tb[TCA_BPF_OPS_LEN]);
    if (bpf_num_ops > BPF_MAXINSNS || bpf_num_ops == 0) return -EINVAL;

    // bpf长度检查
    bpf_size = bpf_num_ops * sizeof(*bpf_ops);
    if (bpf_size != nla_len(tb[TCA_BPF_OPS])) return -EINVAL;

    // 复制`BPF_OPS`指令
    bpf_ops = kmemdup(nla_data(tb[TCA_BPF_OPS]), bpf_size, GFP_KERNEL);
    if (bpf_ops == NULL) return -ENOMEM;

    fprog_tmp.len = bpf_num_ops;
    fprog_tmp.filter = bpf_ops;

    // 创建bpf程序
    ret = bpf_prog_create(&fp, &fprog_tmp);
    if (ret < 0) { 
        kfree(bpf_ops);
        return ret;
    }

    // 设置cls_bpf程序属性
    prog->bpf_ops = bpf_ops;
    prog->bpf_num_ops = bpf_num_ops;
    prog->bpf_name = NULL;
    prog->filter = fp;
    return 0;
}
```

`cls_bpf_prog_from_efd` 函数通过fd方式加载BPF程序，如下：

```C
// file: net/sched/cls_bpf.c
static int cls_bpf_prog_from_efd(struct nlattr **tb, struct cls_bpf_prog *prog, u32 gen_flags, const struct tcf_proto *tp)
{
    struct bpf_prog *fp;
    char *name = NULL;
    bool skip_sw;
    u32 bpf_fd;

    bpf_fd = nla_get_u32(tb[TCA_BPF_FD]);
    skip_sw = gen_flags & TCA_CLS_FLAGS_SKIP_SW;

    // 获取bpf程序
    fp = bpf_prog_get_type_dev(bpf_fd, BPF_PROG_TYPE_SCHED_CLS, skip_sw);
    if (IS_ERR(fp)) return PTR_ERR(fp);

    // 获取bpf程序名称
    if (tb[TCA_BPF_NAME]) {
        name = nla_memdup(tb[TCA_BPF_NAME], GFP_KERNEL);
        if (!name) { ... }
    }

    prog->bpf_ops = NULL;
    prog->bpf_name = name;
    prog->filter = fp;

    // bpf程序需要dst信息时，通知tcf_block保留dst
    if (fp->dst_needed) 
        tcf_block_netif_keep_dst(tp->chain->block);
    return 0;
}
```

#### (4) `delete`接口实现

`cls_bpf_delete` 函数删除`cls_bpf`程序，如下：

```C
// file: net/sched/cls_bpf.c
static int cls_bpf_delete(struct tcf_proto *tp, void *arg, bool *last,
        bool rtnl_held, struct netlink_ext_ack *extack)
{
    struct cls_bpf_head *head = rtnl_dereference(tp->root);

    __cls_bpf_delete(tp, arg, extack);
    *last = list_empty(&head->plist);
    return 0;
}
```

`__cls_bpf_delete` 函数删除指定的cls_bpf程序，如下：

```C
// file: net/sched/cls_bpf.c
static void __cls_bpf_delete(struct tcf_proto *tp, struct cls_bpf_prog *prog, struct netlink_ext_ack *extack)
{
    struct cls_bpf_head *head = rtnl_dereference(tp->root);

    // 归还cls_bpf程序的id
    idr_remove(&head->handle_idr, prog->handle);
    // 取消硬件TC offload
    cls_bpf_stop_offload(tp, prog, extack);
    // 从列表中删除
    list_del_rcu(&prog->link);
    // 取消classid绑定
    tcf_unbind_filter(tp, &prog->res);
    // 删除cls_bpf程序
    if (tcf_exts_get_net(&prog->exts))
        tcf_queue_work(&prog->rwork, cls_bpf_delete_prog_work);
    else
        __cls_bpf_delete_prog(prog);
}
```

`cls_bpf_delete_prog_work` 函数调用`__cls_bpf_delete_prog`函数，后者实现如下：

```C
// file: net/sched/cls_bpf.c
static void __cls_bpf_delete_prog(struct cls_bpf_prog *prog)
{
    // 销毁cls_act
    tcf_exts_destroy(&prog->exts);
    tcf_exts_put_net(&prog->exts);

    // 释放bpf程序
    cls_bpf_free_parms(prog);
    kfree(prog);
}
```

#### (5) `destroy`接口实现

`cls_bpf_destroy` 函数销毁`cls_bpf_head`，如下：

```C
// file: net/sched/cls_bpf.c
static void cls_bpf_destroy(struct tcf_proto *tp, bool rtnl_held, struct netlink_ext_ack *extack)
{
    struct cls_bpf_head *head = rtnl_dereference(tp->root);
    struct cls_bpf_prog *prog, *tmp;

    // 删除所有的cls_bpf程序
    list_for_each_entry_safe(prog, tmp, &head->plist, link)
        __cls_bpf_delete(tp, prog, extack);

    // 销毁idr、释放head
    idr_destroy(&head->handle_idr);
    kfree_rcu(head, rcu);
}
```

### 4.7 `tcf_exts`的实现

`tcf_exts`依赖于`CONFIG_NET_CLS`和`CONFIG_NET_CLS_ACT`内核编译选项，在两者都开启的情况下，实现过程如下：

#### (1) 初始化阶段

`tcf_exts_init` 函数实现`tcf_exts`的初始化，分配`actions`的内存空间，如下：

```C
// file: include/net/pkt_cls.h
static inline int tcf_exts_init(struct tcf_exts *exts, struct net *net, int action, int police)
{
    return tcf_exts_init_ex(exts, net, action, police, NULL, 0, false);
}

// file: net/sched/cls_api.c
int tcf_exts_init_ex(struct tcf_exts *exts, struct net *net, int action, 
        int police, struct tcf_proto *tp, u32 handle, bool use_action_miss)
{
    int err = 0;

    exts->type = 0;
    exts->nr_actions = 0;
    exts->miss_cookie_node = NULL;
    exts->net = net;
    // 32个action
    exts->actions = kcalloc(TCA_ACT_MAX_PRIO, sizeof(struct tc_action *), GFP_KERNEL);
    if (!exts->actions) return -ENOMEM;

    // 设置 action 和 police
    exts->action = action;
    exts->police = police;

    // 不使用`miss_cookie`时，返回
    if (!use_action_miss) return 0;
    // 使用`miss_cookie`时，创建
    err = tcf_exts_miss_cookie_base_alloc(exts, tp, handle);
    if (err) goto err_miss_alloc;

    return 0;
err_miss_alloc:
    tcf_exts_destroy(exts);
    exts->actions = NULL;
    return err;
}
```

#### (2) 验证阶段

`tcf_exts_validate` 函数验证`tcf_exts`，在此阶段初始化`action`，如下：

```C
// file: net/sched/cls_api.c
int tcf_exts_validate(struct net *net, struct tcf_proto *tp, struct nlattr **tb,
    struct nlattr *rate_tlv, struct tcf_exts *exts, u32 flags, struct netlink_ext_ack *extack)
{
    return tcf_exts_validate_ex(net, tp, tb, rate_tlv, exts, flags, 0, extack);
}
// file: net/sched/cls_api.c
int tcf_exts_validate_ex(struct net *net, struct tcf_proto *tp, struct nlattr **tb, struct nlattr *rate_tlv, 
    struct tcf_exts *exts, u32 flags, u32 fl_flags, struct netlink_ext_ack *extack)
{
    int init_res[TCA_ACT_MAX_PRIO] = {};
    struct tc_action *act;
    size_t attr_size = 0;

    if (exts->police && tb[exts->police]) {
        // 设置`police`选项时，只初始化第一个action

        struct tc_action_ops *a_o;
        // 获取 `action_ops`
        a_o = tc_action_load_ops(tb[exts->police], true, !(flags & TCA_ACT_FLAGS_NO_RTNL), extack);
        if (IS_ERR(a_o)) return PTR_ERR(a_o);

        // 初始化一个action
        flags |= TCA_ACT_FLAGS_POLICE | TCA_ACT_FLAGS_BIND;
        act = tcf_action_init_1(net, tp, tb[exts->police], rate_tlv, a_o, init_res, flags, extack);
        module_put(a_o->owner);
        if (IS_ERR(act)) return PTR_ERR(act);

        // `police` 是兼容性设置
        act->type = exts->type = TCA_OLD_COMPAT;
        // 只设置一个action
        exts->actions[0] = act;
        exts->nr_actions = 1;
        // 提交actions， 设置idr
        tcf_idr_insert_many(exts->actions);
    } else if (exts->action && tb[exts->action]) {
        int err; 
        // 初始化多个action
        flags |= TCA_ACT_FLAGS_BIND;
        err = tcf_action_init(net, tp, tb[exts->action], rate_tlv, exts->actions, init_res,
                    &attr_size, flags, fl_flags, extack);
        if (err < 0) return err;
        // 设置actions数量
        exts->nr_actions = err;
    }
    return 0;
}
```

`tcf_action_init` 函数初始化多个action，如下：

```C
// file: net/sched/act_api.c
int tcf_action_init(struct net *net, struct tcf_proto *tp, struct nlattr *nla, struct nlattr *est, 
        struct tc_action *actions[], int init_res[], size_t *attr_size, u32 flags, u32 fl_flags,
        struct netlink_ext_ack *extack)
{
    struct tc_action_ops *ops[TCA_ACT_MAX_PRIO] = {};
    struct nlattr *tb[TCA_ACT_MAX_PRIO + 1];
    struct tc_action *act;
    ...

    // 解析netlink请求
    err = nla_parse_nested_deprecated(tb, TCA_ACT_MAX_PRIO, nla, NULL, extack);
    if (err < 0) return err;

    for (i = 1; i <= TCA_ACT_MAX_PRIO && tb[i]; i++) {
        struct tc_action_ops *a_o;
        // 获取 `action_ops`
        a_o = tc_action_load_ops(tb[i], flags & TCA_ACT_FLAGS_POLICE, !(flags & TCA_ACT_FLAGS_NO_RTNL), extack); 
        if (IS_ERR(a_o)) { ... }
        ops[i - 1] = a_o;
    }

    for (i = 1; i <= TCA_ACT_MAX_PRIO && tb[i]; i++) {
        // 初始化一个action
        act = tcf_action_init_1(net, tp, tb[i], est, ops[i - 1], &init_res[i - 1], flags, extack);
        if (IS_ERR(act)) { ... }

        // action填充大小
        sz += tcf_action_fill_size(act);
        actions[i - 1] = act;

        if (tc_act_bind(flags)) { 
            // 检查绑定属性设置
        } else {
            // 添加 action offload
            err = tcf_action_offload_add(act, extack);
            if (tc_act_skip_sw(act->tcfa_flags) && err)
                goto err;
        }
    }

    // 提交actions， 设置idr
    tcf_idr_insert_many(actions);

    *attr_size = tcf_action_full_attrs_size(sz);
    err = i - 1;
    goto err_mod;

err:
    tcf_action_destroy(actions, flags & TCA_ACT_FLAGS_BIND);
err_mod:
    for (i = 0; i < TCA_ACT_MAX_PRIO; i++) {
        if (ops[i]) module_put(ops[i]->owner);
    }
    return err;
}
```

`tc_action_load_ops` 函数获取`action_ops`，如下：

```C
// file: net/sched/act_api.c
struct tc_action_ops *tc_action_load_ops(struct nlattr *nla, bool police, bool rtnl_held, struct netlink_ext_ack *extack)
{
    struct nlattr *tb[TCA_ACT_MAX + 1];
    struct tc_action_ops *a_o;
    char act_name[IFNAMSIZ];
    struct nlattr *kind;
    int err;

    if (!police) {
        // 不是police模式，通过`ACT_KIND`属性获取
        err = nla_parse_nested_deprecated(tb, TCA_ACT_MAX, nla, tcf_action_policy, extack);
        if (err < 0) return ERR_PTR(err);
        
        err = -EINVAL;
        kind = tb[TCA_ACT_KIND];
        if (!kind) { ... }
        if (nla_strscpy(act_name, kind, IFNAMSIZ) < 0) { ... }
    } else {
        // police模式，固定为`police`
        if (strlcpy(act_name, "police", IFNAMSIZ) >= IFNAMSIZ) { ... }
    }

    // 通过名称获取`action_ops`, 通过`tcf_register_action()`注册的
    a_o = tc_lookup_action_n(act_name);
    if (a_o == NULL) { ... }
    
    return a_o;
}
```

`tcf_action_init_1` 函数初始化一个`action`，如下：

```C
// file: net/sched/act_api.c
struct tc_action *tcf_action_init_1(struct net *net, struct tcf_proto *tp, struct nlattr *nla, 
    struct nlattr *est, struct tc_action_ops *a_o, int *init_res, u32 flags, struct netlink_ext_ack *extack)
{
    bool police = flags & TCA_ACT_FLAGS_POLICE;
    struct nla_bitfield32 userflags = { 0, 0 };
    struct tc_cookie *user_cookie = NULL;
    u8 hw_stats = TCA_ACT_HW_STATS_ANY;
    struct nlattr *tb[TCA_ACT_MAX + 1];
    struct tc_action *a;
    int err;

    if (!police) {
        // action方式时，解析netlink请求
        err = nla_parse_nested_deprecated(tb, TCA_ACT_MAX, nla, tcf_action_policy, extack);
        if (err < 0) return ERR_PTR(err);

        // 设置`COOKIE`选项时，复制到内核中
        if (tb[TCA_ACT_COOKIE]) {
            user_cookie = nla_memdup_cookie(tb);
            if (!user_cookie) { ... }
        }
        // 获取硬件统计方式
        hw_stats = tcf_action_hw_stats_get(tb[TCA_ACT_HW_STATS]);
        // 获取并检查`FLAGS`设置
        if (tb[TCA_ACT_FLAGS]) {
            userflags = nla_get_bitfield32(tb[TCA_ACT_FLAGS]);
            if (!tc_act_flags_valid(userflags.value)) { ... }
        }
        // 初始化action
        err = a_o->init(net, tb[TCA_ACT_OPTIONS], est, &a, tp, userflags.value | flags, extack);
    } else {
        // 初始化action
        err = a_o->init(net, nla, est, &a, tp, userflags.value | flags, extack);
    }
    if (err < 0) goto err_out;
    
    // 设置初始化结果
    *init_res = err;

    // 设置 cookie 和 硬件统计方式    
    if (!police && tb[TCA_ACT_COOKIE])
        tcf_set_action_cookie(&a->user_cookie, user_cookie);
    if (!police)
        a->hw_stats = hw_stats;

    return a;

err_out:
    if (user_cookie) {
        kfree(user_cookie->data);
        kfree(user_cookie);
    }
    return ERR_PTR(err);
}
```

#### (3) 销毁阶段

`tcf_exts_destroy` 函数销毁`tcf_exts`，销毁所有的`action`。如下：

```C
// file: net/sched/cls_api.c
void tcf_exts_destroy(struct tcf_exts *exts)
{
    // 销毁`miss_cookie`
    tcf_exts_miss_cookie_base_destroy(exts);

    if (exts->actions) {
        tcf_action_destroy(exts->actions, TCA_ACT_UNBIND);
        kfree(exts->actions);
    }
    exts->nr_actions = 0;
}
```

`tcf_action_destroy` 函数销毁所有的`action`。如下：

```C
// file: net/sched/act_api.c
int tcf_action_destroy(struct tc_action *actions[], int bind)
{
    const struct tc_action_ops *ops;
    struct tc_action *a;
    int ret = 0, i;

    for (i = 0; i < TCA_ACT_MAX_PRIO && actions[i]; i++) {
        a = actions[i];
        actions[i] = NULL;
        ops = a->ops;
        // 逐个释放action
        ret = __tcf_idr_release(a, bind, true);
        // 返回值判断
        if (ret == ACT_P_DELETED) module_put(ops->owner);
        else if (ret < 0) return ret;
    }
    return ret;
}
```

#### (4) `action`的netlink接口

在创建`cls_bpf`过程中创建`tc_action`，除此之外，Linux内核还提供了专门操作action的接口。如下：

```C
// file: net/sched/act_api.c
static int __init tc_action_init(void)
{
    rtnl_register(PF_UNSPEC, RTM_NEWACTION, tc_ctl_action, NULL, 0);
    rtnl_register(PF_UNSPEC, RTM_DELACTION, tc_ctl_action, NULL, 0);
    rtnl_register(PF_UNSPEC, RTM_GETACTION, tc_ctl_action, tc_dump_action, 0);
	return 0;
}
subsys_initcall(tc_action_init);
```

`tc_ctl_action` 函数实现action的添加、删除、获取操作，如下：

```C
// file: net/sched/act_api.c
static int tc_ctl_action(struct sk_buff *skb, struct nlmsghdr *n, struct netlink_ext_ack *extack)
{
    struct net *net = sock_net(skb->sk);
    struct nlattr *tca[TCA_ROOT_MAX + 1];
    u32 portid = NETLINK_CB(skb).portid;
    u32 flags = 0;
    int ret = 0;

    // 权限检查
    if ((n->nlmsg_type != RTM_GETACTION) && !netlink_capable(skb, CAP_NET_ADMIN))
        return -EPERM;
    // 解析netlink请求信息
    ret = nlmsg_parse_deprecated(n, sizeof(struct tcamsg), tca, TCA_ROOT_MAX, NULL, extack);
    if (ret < 0) return ret;

    // 必须设置`TCA_ACT_TAB`
    if (tca[TCA_ACT_TAB] == NULL) { ... }

	switch (n->nlmsg_type) {
	case RTM_NEWACTION:
        if (n->nlmsg_flags & NLM_F_REPLACE)
            flags = TCA_ACT_FLAGS_REPLACE;
        // 添加action
        ret = tcf_action_add(net, tca[TCA_ACT_TAB], n, portid, flags, extack);
        break;
    case RTM_DELACTION:
        ret = tca_action_gd(net, tca[TCA_ACT_TAB], n, portid, RTM_DELACTION, extack);
        break;
    case RTM_GETACTION:
        ret = tca_action_gd(net, tca[TCA_ACT_TAB], n, portid, RTM_GETACTION, extack);
        break;
    default:
        BUG();
    }
    return ret;
}
```

`tcf_action_add` 函数添加action，如下：

```C
// file: net/sched/act_api.c
static int tcf_action_add(struct net *net, struct nlattr *nla, 
    struct nlmsghdr *n, u32 portid, u32 flags, struct netlink_ext_ack *extack)
{
    size_t attr_size = 0;
    int loop, ret, i;
    struct tc_action *actions[TCA_ACT_MAX_PRIO] = {};
    int init_res[TCA_ACT_MAX_PRIO] = {};

    for (loop = 0; loop < 10; loop++) {
        // 初始化多个action
        ret = tcf_action_init(net, NULL, nla, NULL, actions, init_res, 
            &attr_size, flags, 0, extack);
        if (ret != -EAGAIN) break;
    }

    if (ret < 0) return ret;
    ret = tcf_add_notify(net, n, actions, portid, attr_size, extack);

    // 只释放已存在的action
    for (i = 0; i < TCA_ACT_MAX_PRIO; i++)
        if (init_res[i] == ACT_P_CREATED)
            actions[i] = NULL;
    tcf_action_put_many(actions);
    return ret;
}
```

### 4.8 `act_bpf`的实现

Linux内核支持多种类型的`tcf_action`，在通过`tcf_proto`实现网络数据包的分类后，使用`tc_action`决定网络数据包的执行操作。使用BPF程序时，使用`bpf`类型的`tcf_action`，定义如下：

```C
// file: net/sched/act_bpf.c
static struct tc_action_ops act_bpf_ops __read_mostly = {
	.kind		=	"bpf",
	.id		=	TCA_ID_BPF,
	.owner		=	THIS_MODULE,
	.act		=	tcf_bpf_act,
	.dump		=	tcf_bpf_dump,
	.cleanup	=	tcf_bpf_cleanup,
	.init		=	tcf_bpf_init,
	.size		=	sizeof(struct tcf_bpf),
};
```

在`initcall`阶段注册的，如下：

```C
// file: net/sched/act_bpf.c
static int __init bpf_init_module(void)
{
    return tcf_register_action(&act_bpf_ops, &bpf_net_ops);
}
module_init(bpf_init_module);
```

#### (1) 网络命名空间初始化和清理过程

在`bpf_init_module`初始化过程，注册了`bpf_net_ops`操作接口，如下：

```C
// file: net/sched/act_bpf.c
static struct pernet_operations bpf_net_ops = {
	.init = bpf_init_net,
	.exit_batch = bpf_exit_net,
	.id   = &act_bpf_ops.net_id,
	.size = sizeof(struct tc_action_net),
};
```

`.init`接口在网络命名空间创建时调用，设置为`bpf_init_net`，如下：

```C
// file: net/sched/act_bpf.c
static __net_init int bpf_init_net(struct net *net)
{
    struct tc_action_net *tn = net_generic(net, act_bpf_ops.net_id);
    return tc_action_net_init(net, tn, &act_bpf_ops);
}
```

`net_generic` 函数获取`act_bpf`在网络命名空间存放的私有变量，`struct pernet_operations`结构中的`id` 和 `size` 表示该私有变量的id和大小。如下：

```C
// file: include/net/netns/generic.h
static inline void *net_generic(const struct net *net, unsigned int id)
{
    struct net_generic *ng;
    void *ptr;
    rcu_read_lock();
    ng = rcu_dereference(net->gen);
    ptr = ng->ptr[id];
    rcu_read_unlock();
    return ptr;
}
```

`tc_action_net_init` 函数初始化`tc_action_net`，创建`tc_action`需要的信息，如下：

```C
// file: include/net/act_api.h
static inline int tc_action_net_init(struct net *net, struct tc_action_net *tn, 
    const struct tc_action_ops *ops)
{
    int err = 0;
    // 创建idr
    tn->idrinfo = kmalloc(sizeof(*tn->idrinfo), GFP_KERNEL);
    if (!tn->idrinfo) return -ENOMEM;
    // 设置ops和初始化idr
    tn->ops = ops;
    tn->idrinfo->net = net;
    mutex_init(&tn->idrinfo->lock);
    idr_init(&tn->idrinfo->action_idr);
    return err;
}
```

在销毁网络命名空间后，调用`.exit`接口进行相关清理操作，设置为`bpf_exit_net`，清理`tc_action_net`，如下：

```C
// file: net/sched/act_bpf.c
static void __net_exit bpf_exit_net(struct list_head *net_list)
{
    tc_action_net_exit(net_list, act_bpf_ops.net_id);
}
// file: include/net/act_api.h
static inline void tc_action_net_exit(struct list_head *net_list, unsigned int id)
{
    struct net *net;
    rtnl_lock();
    list_for_each_entry(net, net_list, exit_list) {
        struct tc_action_net *tn = net_generic(net, id);
        // 销毁idr
        tcf_idrinfo_destroy(tn->ops, tn->idrinfo);
        kfree(tn->idrinfo);
    }
    rtnl_unlock();
}
```

#### (2) 初始化过程

`act_bpf`的`.init`接口设置为`tcf_bpf_init`，实现如下：

```C
// file: net/sched/act_bpf.c
static int tcf_bpf_init(struct net *net, struct nlattr *nla, struct nlattr *est, 
    struct tc_action **act, struct tcf_proto *tp, u32 flags, struct netlink_ext_ack *extack)
{
    struct tc_action_net *tn = net_generic(net, act_bpf_ops.net_id);
    bool bind = flags & TCA_ACT_FLAGS_BIND;
    struct nlattr *tb[TCA_ACT_BPF_MAX + 1];
    struct tcf_chain *goto_ch = NULL;
    struct tcf_bpf_cfg cfg, old;
    struct tc_act_bpf *parm;
    ...

    // 解析netlink请求信息
    if (!nla) return -EINVAL;
    ret = nla_parse_nested_deprecated(tb, TCA_ACT_BPF_MAX, nla, act_bpf_policy, NULL);
    if (ret < 0) return ret;
    if (!tb[TCA_ACT_BPF_PARMS]) return -EINVAL;

    // 获取设置的`tc_act_bpf`信息
    parm = nla_data(tb[TCA_ACT_BPF_PARMS]);

    // 检查index是否存在，
    index = parm->index;
    ret = tcf_idr_check_alloc(tn, &index, act, bind);
    if (!ret) {
        // index不存在时，创建`tc_action`
        ret = tcf_idr_create(tn, index, est, act, &act_bpf_ops, bind, true, flags);
        if (ret < 0) { ...}
		res = ACT_P_CREATED;
    } else if (ret > 0) {
        // 存在时，检查是否替换
        if (bind) return 0;
        if (!(flags & TCA_ACT_FLAGS_REPLACE)) { ... }
    } else {
        return ret;
    }

    // 检查`action`参数情况，在设置`TC_ACT_GOTO_CHAIN`时，从`block`中获取跳转的`chain`
    ret = tcf_action_check_ctrlact(parm->action, tp, &goto_ch, extack);
    if (ret < 0) goto release_idr;

    // 检查设置bpf程序方式，可以通过指令和fd方式设置
    is_bpf = tb[TCA_ACT_BPF_OPS_LEN] && tb[TCA_ACT_BPF_OPS];
    is_ebpf = tb[TCA_ACT_BPF_FD];
    if (is_bpf == is_ebpf) { ... }

    memset(&cfg, 0, sizeof(cfg));
    // 获取bpf程序，通过fd获取时，程序类型为`BPF_PROG_TYPE_SCHED_ACT`
    ret = is_bpf ? tcf_bpf_init_from_ops(tb, &cfg) :
                tcf_bpf_init_from_efd(tb, &cfg);
    if (ret < 0) goto put_chain;

    prog = to_bpf(*act);

    spin_lock_bh(&prog->tcf_lock);
    // 存在bpf程序，填充到旧的配置中，后续释放
    if (res != ACT_P_CREATED) tcf_bpf_prog_fill_cfg(prog, &old);

    // 设置`act_bpf`程序属性
    prog->bpf_ops = cfg.bpf_ops;
    prog->bpf_name = cfg.bpf_name;
    if (cfg.bpf_num_ops)
        prog->bpf_num_ops = cfg.bpf_num_ops;
    // 设置`tc_action`跳转chain，设置`act->tcfa_action`和`act->goto_chain`属性
    goto_ch = tcf_action_set_ctrlact(*act, parm->action, goto_ch);
    // 设置bpf程序
    rcu_assign_pointer(prog->filter, cfg.filter);
    spin_unlock_bh(&prog->tcf_lock);

    // 释放之前设置的跳转chain
    if (goto_ch)
        tcf_chain_put_by_act(goto_ch);

    if (res != ACT_P_CREATED) {
        synchronize_rcu();
        // 替换`act_bpf`时，释放之前的bpf程序
        tcf_bpf_cfg_cleanup(&old);
    }
    return res;
}
```

#### (3) 清理过程

`act_bpf`的`.cleanup`接口设置为`tcf_bpf_cleanup`，实现如下：

```C
// file: net/sched/act_bpf.c
static void tcf_bpf_cleanup(struct tc_action *act)
{
    struct tcf_bpf_cfg tmp;
    // 获取bpf信息后清理
    tcf_bpf_prog_fill_cfg(to_bpf(act), &tmp);
    tcf_bpf_cfg_cleanup(&tmp);
}
// file: net/sched/act_bpf.c
static void tcf_bpf_cfg_cleanup(const struct tcf_bpf_cfg *cfg)
{
    struct bpf_prog *filter = cfg->filter;
    // 释放bpf程序
    if (filter) {
        if (cfg->is_ebpf) bpf_prog_put(filter);
        else bpf_prog_destroy(filter);
	}
    kfree(cfg->bpf_ops);
    kfree(cfg->bpf_name);
}
```

### 4.9 `tc`的实现过程

#### (1) 网络数据接收(INGRESS)路径的实现过程

`__netif_receive_skb_core` 函数将skb发送内核网络协议栈，在 [XDP的内核实现](./12-xdp.md) 中我们分析了XDP的实现过程，[SOCKFILTER的内核实现](./13-sockfilter.md) 中分析了网络抓包的实现过程，下一步就是TC处理。如下：

```C
// file: net/core/dev.c
static int __netif_receive_skb_core(struct sk_buff **pskb, bool pfmemalloc, struct packet_type **ppt_prev)
{
    ...
skip_taps:
    if (static_branch_unlikely(&ingress_needed_key)) {
        bool another = false;
        nf_skip_egress(skb, true);
        // ingress路径实现TC
        skb = sch_handle_ingress(skb, &pt_prev, &ret, orig_dev, &another);
        // 判断是否重新处理
        if (another) goto another_round;
        // skb被过滤，跳过处理
        if (!skb) goto out;
        
        nf_skip_egress(skb, false);
        // netfilter ingress 处理
        if (nf_ingress(skb, &pt_prev, &ret, orig_dev) < 0) goto out;
    }
    skb_reset_redirect(skb);
    ...
}
```

`sch_handle_ingress` 函数实现ingress路径TC的处理，如下：

```C
// file: net/core/dev.c
static inline struct sk_buff * sch_handle_ingress(struct sk_buff *skb, struct packet_type **pt_prev, 
    int *ret, struct net_device *orig_dev, bool *another)
{
    // 获取 miniq_ingress
    struct mini_Qdisc *miniq = rcu_dereference_bh(skb->dev->miniq_ingress);
    struct tcf_result cl_res;

    if (!miniq) return skb;

    if (*pt_prev) {
        // 传送skb
        *ret = deliver_skb(skb, *pt_prev, orig_dev);
        *pt_prev = NULL;
    }

    // skb->cb 属性设置后，更新流量统计信息
    qdisc_skb_cb(skb)->pkt_len = skb->len;
    tc_skb_cb(skb)->mru = 0;
    tc_skb_cb(skb)->post_ct = false;
    skb->tc_at_ingress = 1;
    mini_qdisc_bstats_cpu_update(miniq, skb);

    switch (tcf_classify(skb, miniq->block, miniq->filter_list, &cl_res, false)) {
    case TC_ACT_OK:
    case TC_ACT_RECLASSIFY:
        // 设置`tc_index`为`classid`
        skb->tc_index = TC_H_MIN(cl_res.classid);
        break;
    case TC_ACT_SHOT:
        // 丢弃skb，统计丢弃计数后释放skb，返回结果表示丢弃
        mini_qdisc_qstats_cpu_drop(miniq);
        kfree_skb_reason(skb, SKB_DROP_REASON_TC_INGRESS);
        *ret = NET_RX_DROP;
        return NULL;
    case TC_ACT_STOLEN:
    case TC_ACT_QUEUED:
    case TC_ACT_TRAP:
        // 释放skb，返回结果表示正确接收
        consume_skb(skb);
        *ret = NET_RX_SUCCESS;
        return NULL;
    case TC_ACT_REDIRECT:
        // 重定向skb，`EAGAIN`错误时重新开始处理
        __skb_push(skb, skb->mac_len);
        if (skb_do_redirect(skb) == -EAGAIN) {
            __skb_pull(skb, skb->mac_len);
            *another = true;
            break;
        }
        *ret = NET_RX_SUCCESS;
        return NULL;
    case TC_ACT_CONSUMED:
        *ret = NET_RX_SUCCESS;
        return NULL;
    default:
        break;
    }
    return skb;
}
```

#### (2) 网络数据发送(EGRESS)路径的实现过程

在使用 `dev_queue_xmit` 方式发送的网络数据包过程中，在发送之前实现TC处理，如下：

```C
// file: net/core/dev.c
int __dev_queue_xmit(struct sk_buff *skb, struct net_device *sb_dev)
{
    ...
    skb->tc_at_ingress = 0;
    if (static_branch_unlikely(&egress_needed_key)) {
        // netfilter egress 处理
        if (nf_hook_egress_active()) {
            skb = nf_hook_egress(skb, &rc, dev);
            if (!skb) goto out;
        }
        netdev_xmit_skip_txqueue(false);
        nf_skip_egress(skb, true);

        // egress路径实现TC
        skb = sch_handle_egress(skb, &rc, dev);
        // skb被过滤，跳过处理
        if (!skb) goto out;
        nf_skip_egress(skb, false);

        if (netdev_xmit_txqueue_skipped())
            txq = netdev_tx_queue_mapping(dev, skb);
    }
    ...
}
```

`sch_handle_egress` 函数实现egress路径TC的处理，如下：

```C
// file: net/core/dev.c
static struct sk_buff * sch_handle_egress(struct sk_buff *skb, int *ret, struct net_device *dev)
{
    // 获取 miniq_egress
    struct mini_Qdisc *miniq = rcu_dereference_bh(dev->miniq_egress);
    struct tcf_result cl_res;

    if (!miniq) return skb;

    // skb->cb 属性设置后，更新流量统计信息
    tc_skb_cb(skb)->mru = 0;
    tc_skb_cb(skb)->post_ct = false;
    mini_qdisc_bstats_cpu_update(miniq, skb);

    switch (tcf_classify(skb, miniq->block, miniq->filter_list, &cl_res, false)) {
    case TC_ACT_OK:
    case TC_ACT_RECLASSIFY:
        // 设置`tc_index`为`classid`
        skb->tc_index = TC_H_MIN(cl_res.classid);
        break;
    case TC_ACT_SHOT:
        // 丢弃skb，统计丢弃计数后释放skb，返回结果表示丢弃
        mini_qdisc_qstats_cpu_drop(miniq);
        *ret = NET_XMIT_DROP;
        kfree_skb_reason(skb, SKB_DROP_REASON_TC_EGRESS);
        return NULL;
    case TC_ACT_STOLEN:
    case TC_ACT_QUEUED:
    case TC_ACT_TRAP:
        // 释放skb，返回结果表示正确发送
        *ret = NET_XMIT_SUCCESS;
        consume_skb(skb);
        return NULL;
    case TC_ACT_REDIRECT:
        // 重定向skb，返回结果表示正确发送
        skb_do_redirect(skb);
        *ret = NET_XMIT_SUCCESS;
        return NULL;
    default:
        break;
    }
    return skb;
}
```

#### (3) `tcf_classify`的实现过程

INGRESS和EGRESS路径上都调用`tcf_classify`函数实现TC的核心处理，如下：

```C
// file: net/sched/cls_api.c
int tcf_classify(struct sk_buff *skb, const struct tcf_block *block,
        const struct tcf_proto *tp, struct tcf_result *res, bool compat_mode)
{
    u32 last_executed_chain = tp ? tp->chain->index : 0;
    struct tcf_exts_miss_cookie_node *n = NULL;
    const struct tcf_proto *orig_tp = tp;
    struct tc_skb_ext *ext;
    int act_index = 0;
    int ret;

    if (block) {
        // `block`存在时，获取`skb_ext`，获取上次执行状态
        ext = skb_ext_find(skb, TC_SKB_EXT);
        if (ext && (ext->chain || ext->act_miss)) {
            struct tcf_chain *fchain;
            u32 chain;
            // `act_miss`状态时，通过`miss_cookie`获取action和chain
            if (ext->act_miss) {
                n = tcf_exts_miss_cookie_lookup(ext->act_miss_cookie, &act_index);
                // `miss_cookie`不存在时，返回`TC_ACT_SHOT`
                if (!n) return TC_ACT_SHOT;
                // 获取chain
                chain = n->chain_index;
            } else {
                chain = ext->chain;
            }
            // 获取`chain`, 不存在时，返回`TC_ACT_SHOT`
            fchain = tcf_chain_lookup_rcu(block, chain);
            if (!fchain) return TC_ACT_SHOT;

            // 删除`SKB_EXT`, 复制或重定向的skb不继承
            skb_ext_del(skb, TC_SKB_EXT);

            // 获取`tcf_proto`和上次执行的`chain`
            tp = rcu_dereference_bh(fchain->filter_chain);
            last_executed_chain = fchain->index;
        }
    }

    // 主要的`classifier`过程
    ret = __tcf_classify(skb, tp, orig_tp, res, compat_mode, n, act_index, &last_executed_chain);

    if (tc_skb_ext_tc_enabled()) {
        // 错过了一些chain，设置skb_ext
        if (ret == TC_ACT_UNSPEC && last_executed_chain) {
            struct tc_skb_cb *cb = tc_skb_cb(skb);
            // 分配skb_ext，分配失败时，返回`TC_ACT_SHOT`
            ext = tc_skb_ext_alloc(skb);
            if (WARN_ON_ONCE(!ext))
                return TC_ACT_SHOT;
            // 设置skb_ext信息
            ext->chain = last_executed_chain;
            ext->mru = cb->mru;
            ext->post_ct = cb->post_ct;
            ext->post_ct_snat = cb->post_ct_snat;
            ext->post_ct_dnat = cb->post_ct_dnat;
            ext->zone = cb->zone;
        }
    }
    return ret;
}
```

`__tcf_classify` 函数是主要的分类器实现，遍历附加到qdisc上的classifier链表，逐个执行`tc_action`和`tc_cls`，如下：

```C
// file: net/sched/cls_api.c
static inline int __tcf_classify(struct sk_buff *skb, const struct tcf_proto *tp, 
    const struct tcf_proto *orig_tp, struct tcf_result *res, bool compat_mode, 
    struct tcf_exts_miss_cookie_node *n, int act_index, u32 *last_executed_chain)
{
    const int max_reclassify_loop = 16;
    const struct tcf_proto *first_tp;
    int limit = 0;

reclassify:
    for (; tp; tp = rcu_dereference_bh(tp->next)) {
        // 获取网络协议
        __be16 protocol = skb_protocol(skb, false);
        int err = 0;

        if (n) {
            // `exts_miss_cookie`存在时
            struct tcf_exts *exts;
            // 优先级不同时，继续下一个
            if (n->tp_prio != tp->prio) continue;

            // 重新获取tp，检查硬件中的cookie是否替换了相关字段，不同时返回`TC_ACT_SHOT`
            if (unlikely(n->tp != tp || n->tp->chain != n->chain || !tp->ops->get_exts))
                return TC_ACT_SHOT;
            exts = tp->ops->get_exts(tp, n->handle);
            if (unlikely(!exts || n->exts != exts))
                return TC_ACT_SHOT;

            // 执行`tc_act`
            n = NULL;
            err = tcf_exts_exec_ex(skb, exts, act_index, res);
        } else {
            // 检查网络协议是否相同，不同时，继续下一个
            if (tp->protocol != protocol && tp->protocol != htons(ETH_P_ALL))
                continue;
            // 执行`tc_classify`
            err = tc_classify(skb, tp, res);
        }
        if (unlikely(err == TC_ACT_RECLASSIFY && !compat_mode)) {
            // 返回结果为`TC_ACT_RECLASSIFY`时，重新分类
            first_tp = orig_tp;
            *last_executed_chain = first_tp->chain->index;
            goto reset;
        } else if (unlikely(TC_ACT_EXT_CMP(err, TC_ACT_GOTO_CHAIN))) {
            // 返回结果为`TC_ACT_GOTO_CHAIN`, 跳转到其他`tcf_proto`继续分类
            first_tp = res->goto_tp;
            *last_executed_chain = err & TC_ACT_EXT_VAL_MASK;
            goto reset;
        }
        // 获取判决结果后返回
        if (err >= 0) return err;
    }
    // `exts_miss_cookie`存在，但未执行，返回`TC_ACT_SHOT`
    if (unlikely(n)) return TC_ACT_SHOT;

    // 默认返回`TC_ACT_UNSPEC`, 继续下阶段处理
    return TC_ACT_UNSPEC; 
reset:
    // 超过循环限制时，返回`TC_ACT_SHOT`
    if (unlikely(limit++ >= max_reclassify_loop)) {
        return TC_ACT_SHOT;
    }
    // 设置开始的`tcf_proto`后，继续分类
    tp = first_tp;
    goto reclassify;
}
```

#### (4) `tc_actions`的执行过程

`tcf_exts_exec_ex` 函数执行tc filter的扩展，即执行`tc_action`，如下：

```C
// file: include/net/pkt_cls.h
static inline int tcf_exts_exec_ex(struct sk_buff *skb, struct tcf_exts *exts, int act_index, struct tcf_result *res)
{
#ifdef CONFIG_NET_CLS_ACT
	return tcf_action_exec(skb, exts->actions + act_index, exts->nr_actions - act_index, res);
#else
	return TC_ACT_OK;
#endif
}
```

`tcf_action_exec` 函数执行`tc_action`，如下：

```C
// file: net/sched/act_api.c
#define TCA_ACT_MAX_PRIO_MASK 0x1FF
int tcf_action_exec(struct sk_buff *skb, struct tc_action **actions, int nr_actions, struct tcf_result *res)
{
    u32 jmp_prgcnt = 0;
    u32 jmp_ttl = TCA_ACT_MAX_PRIO; /*matches actions per filter */
    int i;
    int ret = TC_ACT_OK;

    // skb跳过分类时，返回`TC_ACT_OK`
    if (skb_skip_tc_classify(skb))
        return TC_ACT_OK;

restart_act_graph:
    for (i = 0; i < nr_actions; i++) {
        const struct tc_action *a = actions[i];
        int repeat_ttl;

        // 跳过action计数
        if (jmp_prgcnt > 0) {
            jmp_prgcnt -= 1;
            continue;
        }
        // action跳过软件执行时，继续下一个
        if (tc_act_skip_sw(a->tcfa_flags)) continue;

        repeat_ttl = 32;
repeat:
        // 执行`action`
        ret = tc_act(skb, a, res);
        
        // 返回值为`TC_ACT_REPEAT`时，重新执行这个`action`
        if (unlikely(ret == TC_ACT_REPEAT)) {
            if (--repeat_ttl != 0)
                goto repeat;
            // 重复次数超过执行次数时，返回`TC_ACT_OK`
            net_warn_ratelimited("TC_ACT_REPEAT abuse ?\n");
            return TC_ACT_OK;
        }
        if (TC_ACT_EXT_CMP(ret, TC_ACT_JUMP)) {
            // 返回结果为`TC_ACT_JUMP`, 跳过n个action
            // 获取跳过计数，计数超出范围时，返回`TC_ACT_OK`
            jmp_prgcnt = ret & TCA_ACT_MAX_PRIO_MASK;
            if (!jmp_prgcnt || (jmp_prgcnt > nr_actions)) {
                return TC_ACT_OK;
            } else {
                // 减少jmp_ttl，正常时重新执行action，否则返回`TC_ACT_OK`
                jmp_ttl -= 1;
                if (jmp_ttl > 0) goto restart_act_graph;
                else  return TC_ACT_OK;
            }
        } else if (TC_ACT_EXT_CMP(ret, TC_ACT_GOTO_CHAIN)) {
            // 返回结果为`TC_ACT_GOTO_CHAIN`, 跳转到其他chain继续支持
            // 获取跳转的chain失败后，返回`TC_ACT_SHOT`
            if (unlikely(!rcu_access_pointer(a->goto_chain))) {
                return TC_ACT_SHOT;
            }
            // 设置返回结果，设置`goto_tp`
            tcf_action_goto_chain_exec(a, res);
        }
        // 返回值不是`TC_ACT_PIPE`时，跳过剩余的action
        if (ret != TC_ACT_PIPE) break;
    }
    return ret;
}
```

#### (5) `cls_bpf_classify`的实现

`cls_bpf`设置的`.classify`接口为`cls_bpf_classify`，实现如下：

```C
// file: net/sched/cls_bpf.c
TC_INDIRECT_SCOPE int cls_bpf_classify(struct sk_buff *skb, const struct tcf_proto *tp, struct tcf_result *res)
{
    struct cls_bpf_head *head = rcu_dereference_bh(tp->root);
    bool at_ingress = skb_at_tc_ingress(skb);
    struct cls_bpf_prog *prog;
    int ret = -1;

    list_for_each_entry_rcu(prog, &head->plist, link) {
        int filter_res;
        // 设置`classid`
        qdisc_skb_cb(skb)->tc_classid = prog->res.classid;

        if (tc_skip_sw(prog->gen_flags)) {
            // offload时返回值设置，`da`模式时返回`TC_ACT_UNSPEC`
            filter_res = prog->exts_integrated ? TC_ACT_UNSPEC : 0;
        } else if (at_ingress) {
            // ingress路径设置skb，不能修改mac地址
            __skb_push(skb, skb->mac_len);
            bpf_compute_data_pointers(skb);
            // 运行bpf程序
            filter_res = bpf_prog_run(prog->filter, skb);
            __skb_pull(skb, skb->mac_len);
        } else {
            // egress路径设置skb
            bpf_compute_data_pointers(skb);
            // 运行bpf程序
            filter_res = bpf_prog_run(prog->filter, skb);
        }
        // 接收时间未设置时，清除EDT时间
        if (unlikely(!skb->tstamp && skb->mono_delivery_time))
            skb->mono_delivery_time = 0;

        if (prog->exts_integrated) {
            // `da`模式下，设置返回结果
            res->class   = 0;
            res->classid = TC_H_MAJ(prog->res.classid) | qdisc_skb_cb(skb)->tc_classid;
            // 转换返回值
            ret = cls_bpf_exec_opcode(filter_res);
            // `TC_ACT_UNSPEC`时执行下一个bpf程序，其他值表示执行结果，退出执行过程
            if (ret == TC_ACT_UNSPEC)
                continue;
            break;
        }
        // 非`da`模式，检查返回值, 0表示继续执行BPF程序；
        if (filter_res == 0) 
            continue;
        if (filter_res != -1) {
            // 0,-1以外的其他值表示`classid`
            res->class   = 0;
            res->classid = filter_res;
        } else {
            // -1表示使用设置的结果；
            *res = prog->res;
        }
        // 执行`tc_action`，返回值小于0，继续执行，其他值表示执行结果，退出执行过程
        ret = tcf_exts_exec(skb, &prog->exts, res);
        if (ret < 0)
            continue;
        break;
    }
    return ret;
}
```

#### (6) `tcf_bpf_act`的实现

`act_bpf`设置的`.act`接口为`tcf_bpf_act`，实现如下：

```C
// file: net/sched/act_bpf.c
TC_INDIRECT_SCOPE int tcf_bpf_act(struct sk_buff *skb, const struct tc_action *act, struct tcf_result *res)
{
    bool at_ingress = skb_at_tc_ingress(skb);
    struct tcf_bpf *prog = to_bpf(act);
    struct bpf_prog *filter;
    int action, filter_res;

    // 更新`act_bpf`程序执行时间
    tcf_lastuse_update(&prog->tcf_tm);
    // 更新流量统计信息
    bstats_update(this_cpu_ptr(prog->common.cpu_bstats), skb);

    // ingress/egress路径执行bpf程序，获取返回值
    filter = rcu_dereference(prog->filter);
    if (at_ingress) {
        __skb_push(skb, skb->mac_len);
        bpf_compute_data_pointers(skb);
        filter_res = bpf_prog_run(filter, skb);
        __skb_pull(skb, skb->mac_len);
    } else {
        bpf_compute_data_pointers(skb);
        filter_res = bpf_prog_run(filter, skb);
    }
    // 接收时间未设置时，清除EDT时间
    if (unlikely(!skb->tstamp && skb->mono_delivery_time))
        skb->mono_delivery_time = 0;
    // skb提前加载时，且结果不是`TC_ACT_OK`，孤立skb
    if (skb_sk_is_prefetched(skb) && filter_res != TC_ACT_OK)
        skb_orphan(skb);

    // 修正BPF程序执行结果，-1时使用tc指定的默认结果
    switch (filter_res) {
    case TC_ACT_PIPE:
    case TC_ACT_RECLASSIFY:
    case TC_ACT_OK:
    case TC_ACT_REDIRECT:
        action = filter_res;
        break;
    case TC_ACT_SHOT:
        // 丢弃skb，增加丢弃统计计数
        action = filter_res;
        qstats_drop_inc(this_cpu_ptr(prog->common.cpu_qstats));
        break;
    case TC_ACT_UNSPEC:
        // 执行结果为-1时，使用指定的结果
        action = prog->tcf_action;
        break;
    default:
        // 其他值表示未指定，继续执行下一个action或cls
        action = TC_ACT_UNSPEC;
        break;
    }
    return action;
}
```

### 4.10 `tc`重定向实现过程

INGRESS和EGRESS路径上都调用`tcf_classify`函数实现TC的核心处理，返回结果为`TC_ACT_REDIRECT`时，表示需要重定向skb，`skb_do_redirect` 函数实现该功能，如下：

#### (1) `skb_do_redirect`的实现

`skb_do_redirect` 函数获取`bpf_redirect_info`变量设置的重定向信息后，进行不同的处理。如下：

```C
// file: net/core/filter.c
int skb_do_redirect(struct sk_buff *skb)
{
    struct bpf_redirect_info *ri = this_cpu_ptr(&bpf_redirect_info);
    struct net *net = dev_net(skb->dev);
    struct net_device *dev;
    u32 flags = ri->flags;

    dev = dev_get_by_index_rcu(net, ri->tgt_index);
    ri->tgt_index = 0;
    ri->flags = 0;

    // 重定向的设备不存在时，释放skb
    if (unlikely(!dev)) goto out_drop;

    if (flags & BPF_F_PEER) { ... }
    return flags & BPF_F_NEIGH ?
           __bpf_redirect_neigh(skb, dev, flags & BPF_F_NEXTHOP ? &ri->nh : NULL) :
           __bpf_redirect(skb, dev, flags);
out_drop:
    kfree_skb(skb);
    return -EINVAL;
}
```

#### (2) 重定向到peer

在BPF程序中调用 `bpf_redirect_peer` 函数，设置重定向信息，如下：

```C
// file: net/core/filter.c
BPF_CALL_2(bpf_redirect_peer, u32, ifindex, u64, flags)
{
    struct bpf_redirect_info *ri = this_cpu_ptr(&bpf_redirect_info);
    if (unlikely(flags)) 
        return TC_ACT_SHOT;

    ri->flags = BPF_F_PEER;
    ri->tgt_index = ifindex;
    return TC_ACT_REDIRECT;
}
```

在 `skb_do_redirect()` 函数中处理，设置skb的网卡设备为获取的对向设备，获取失败时，释放skb。如下： 

```C
// file: net/core/filter.c
int skb_do_redirect(struct sk_buff *skb)
{
    ...
    if (flags & BPF_F_PEER) {
        const struct net_device_ops *ops = dev->netdev_ops;
        // 在`INGRESS`和`dev`支持时，修改skb->dev，不支持时释放skb
        if (unlikely(!ops->ndo_get_peer_dev || !skb_at_tc_ingress(skb)))
            goto out_drop;
        dev = ops->ndo_get_peer_dev(dev);
        if (unlikely(!dev || !(dev->flags & IFF_UP) || net_eq(net, dev_net(dev))))
            goto out_drop;
        skb->dev = dev;
        return -EAGAIN;
    }
    ...
}
```

#### (3) 重定向到neigh

在BPF程序中调用 `bpf_redirect_neigh` 函数，设置重定向信息，如下：

```C
// file: net/core/filter.c
BPF_CALL_4(bpf_redirect_neigh, u32, ifindex, struct bpf_redir_neigh *, params, int, plen, u64, flags)
{
    struct bpf_redirect_info *ri = this_cpu_ptr(&bpf_redirect_info);

    if (unlikely((plen && plen < sizeof(*params)) || flags))
        return TC_ACT_SHOT;

    ri->flags = BPF_F_NEIGH | (plen ? BPF_F_NEXTHOP : 0);
    ri->tgt_index = ifindex;

    BUILD_BUG_ON(sizeof(struct bpf_redir_neigh) != sizeof(struct bpf_nh_params));
    if (plen)
        memcpy(&ri->nh, params, sizeof(ri->nh));

    return TC_ACT_REDIRECT;
}
```

在 `skb_do_redirect()` 函数中调用 `__bpf_redirect_neigh` 函数处理，将skb重定向到路由信息中，通过IPV4或IPV6路由发送，不支持时释放skb，如下：

```C
// file: net/core/filter.c
static int __bpf_redirect_neigh(struct sk_buff *skb, struct net_device *dev, struct bpf_nh_params *nh)
{
    struct ethhdr *ethh = eth_hdr(skb);
    // skb数据不正确
    if (unlikely(skb->mac_header >= skb->network_header)) 
        goto out;

    // 重新计算校验和
    bpf_push_mac_rcsum(skb);
    // 不支持多播地址转发
    if (is_multicast_ether_addr(ethh->h_dest))
        goto out;

    // 重置skb中l1,l2内容
    skb_pull(skb, sizeof(*ethh));
    skb_unset_mac_header(skb);
    skb_reset_network_header(skb);

    // 检查网络协议，重定向到IPV4或IPV6路由中
    if (skb->protocol == htons(ETH_P_IP))
        return __bpf_redirect_neigh_v4(skb, dev, nh);
    else if (skb->protocol == htons(ETH_P_IPV6))
        return __bpf_redirect_neigh_v6(skb, dev, nh);
out:
    kfree_skb(skb);
    return -ENOTSUPP;
}
```

#### (4) 默认重定向

在BPF程序中调用 `bpf_redirect` 函数，设置重定向信息，如下：

```C
// file: net/core/filter.c
BPF_CALL_2(bpf_redirect, u32, ifindex, u64, flags)
{
    struct bpf_redirect_info *ri = this_cpu_ptr(bpf_redirect_info);

    if (unlikely(flags & (~(BPF_F_INGRESS) | BPF_F_REDIRECT_INTERNAL)))
        return TC_ACT_SHOT;

    ri->flags = flags;
    ri->tgt_index = ifindex;
    return TC_ACT_REDIRECT;
}
```

在 `skb_do_redirect()` 函数中调用 `__bpf_redirect` 函数处理，实现skb的默认重定向，如下：

```C
// file: net/core/filter.c
static int __bpf_redirect(struct sk_buff *skb, struct net_device *dev, u32 flags)
{
    // 检查网卡是否支持mac地址
    if (dev_is_mac_header_xmit(dev))
        return __bpf_redirect_common(skb, dev, flags);
    else
        return __bpf_redirect_no_mac(skb, dev, flags);
}
```

在网卡设备需要mac地址时，进行普通的重定向，如下：

```C
// file: net/core/filter.c
static int __bpf_redirect_common(struct sk_buff *skb, struct net_device *dev, u32 flags)
{
    // 检查链路层是否支持，不支持时释放skb
    if (unlikely(skb->mac_header >= skb->network_header || skb->len == 0)) {
        kfree_skb(skb);
        return -ERANGE;
    }
    // 设置mac后，重新计算skb校验和
    bpf_push_mac_rcsum(skb);
    return flags & BPF_F_INGRESS ? __bpf_rx_skb(dev, skb) : __bpf_tx_skb(dev, skb);
}
```

`__bpf_rx_skb` 函数实现INGRESS路径重定向，在支持转发时，通过`netif_rx_internal()` 函数将skb发送到内核协议栈。如下：

```C
// file: net/core/filter.c
static inline int __bpf_rx_skb(struct net_device *dev, struct sk_buff *skb)
{
    return dev_forward_skb_nomtu(dev, skb);
}
// file: net/core/dev.c
int dev_forward_skb_nomtu(struct net_device *dev, struct sk_buff *skb)
{
    return __dev_forward_skb2(dev, skb, false) ?: netif_rx_internal(skb);
}
```

`__bpf_tx_skb` 函数实现EGRESS路径重定向，设置skb信息后，通过`dev_queue_xmit()`函数发送。如下：

```C
// file: net/core/dev.c
static inline int __bpf_tx_skb(struct net_device *dev, struct sk_buff *skb)
{
    int ret;
    // 重定向次数达到上限(8次)时，释放skb
    if (dev_xmit_recursion()) {
        net_crit_ratelimited("bpf: recursion limit reached on datapath, buggy bpf program?\n");
        kfree_skb(skb);
        return -ENETDOWN;
    }
    // 设置skb信息
    skb->dev = dev;
    skb_clear_tstamp(skb);

    // 发送skb
    dev_xmit_recursion_inc();
    ret = dev_queue_xmit(skb);
    dev_xmit_recursion_dec();
    return ret;
}
```

## 5 总结

本文通过`tc`示例程序分析了Linux内核使用BPF实现流量控制的实现过程，通过qdisc、classifier、action实现对INGRESS和EGRESS路径上skb的控制。在使用BPF进行tc控制时，使用`DA`模式，直接在`cls_bpf`中返回判决结果，不使用额外的`action`，就像`tc`示例程序那样。

## 参考资料

* [Linux 网络栈接收数据（RX）：原理及内核实现（2022）](https://arthurchiao.art/blog/linux-net-stack-implementation-rx-zh/)
* [Linux 网络栈监控和调优：发送数据（2017）](http://arthurchiao.art/blog/tuning-stack-tx-zh/)
* [XDP](https://docs.cilium.io/en/latest/bpf/progtypes/#xdp)
* [Cilium：BPF 和 XDP 参考指南（2021）](https://arthurchiao.art/blog/cilium-bpf-xdp-reference-guide-zh/)
* [迈向完全可编程 tc 分类器（cls_bpf）](https://arthurchiao.art/blog/on-getting-tc-classifier-fully-programmable-zh)
* [深入理解 tc ebpf 的 direct-action (da) 模式](https://arthurchiao.art/blog/understanding-tc-da-mode-zh/)
* [用 tc qdisc 管理 Linux 网络带宽](https://arthurchiao.art/blog/lartc-qdisc-zh/)
* [Linux Networking and Network Devices APIs](https://www.kernel.org/doc/html/latest/networking/kapi.html)